\documentclass{uit-thesis}

\usepackage{enumitem}
\usepackage{/usr/local/texlive/2019/texmf-dist/tex/latex/tlatex/tlatex}
\usepackage[backend=biber, sorting=none]{biblatex}
\usepackage[nottoc,numbib]{tocbibind}
\addbibresource{sources.bib}
\graphicspath{{./figures/}}

\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
% \renewcommand{\implies}{\rightarrow}
\newcommand{\eventually}{\rightsquigarrow}

\usepackage{color}
\definecolor{boxshade}{gray}{0.85}
\setboolean{shading}{true}

\begin{document}

\title{Formal Verification of a Lock-free Split-order Hashmap}
% \subtitle{Subtitle}% Note: this is optional, and may be commented out
\author{Åsmund Aqissiaq Arild Kløvstad}
\thesisfaculty{Faculty of Science and Technology \\ Department of Computer Science}
\thesisprogramme{INF-2990 Bachelor's thesis in Informatics \today{}}

\maketitle

\frontmatter

\begin{epigraph}
\epigraphitem{You don't need to understand everything at once. You understand one thing, then you pat yourself on the back, have a cup of coffee, and understand one more thing.}{Nada Amin}
\end{epigraph}

\tableofcontents

\begin{abstract}
    %purpose/why?
    Concurrent systems are increasingly important in a variety of application domains, but concurrent algorithms and data structures are difficult to design, debug and verify. Formal verification with model checkers is one way to verify concurrent structures by creating a specification of the structure and demonstrating properties by exhaustively checking possible states.\\\\
    One important data structure is the extensible hashmap, and Shalev et al.~\cite{Shalev2006} present a novel lock-free way to implement them.
    \\\\%arguments and claims/what?
    We present a formal specification of Shalev et al.'s lock-free hashmap in a concurrent setting and demonstrate that their claimed invariants hold for a subset of the state space using a model checker. We also discuss the merits of this demonstration and lessons learned from the process.
    \\\\%method/how?
    We produce 4 specifications: a non-concurrent version of the hashmap structure, an idealized hashmap used to check the non-concurrent version, and two versions of the structure used to verify invariants in a concurrent setting. The specifications are written in TLA+ and checked using the TLC model checker.
    \\\\%conclusions
    We conclude that our formal verification gives increased confidence in the correctness of Shalev et al.'s hashmap, but that the method cannot be used as conclusive proof on its own. We also present three concrete lessons about formal verification motivated by experiences during development of the specification; decide on the purpose of a specification early, test assumed invariants, and choose step size early and deliberately.
\end{abstract}

\mainmatter

\chapter{Introduction}
Concurrent and distributed systems are extremely important in modern software development. Due to the difficulty of developing ever smaller and more powerful CPUs the trend in hardware design since about 2005 has been to increase the number of cores to allow for high levels of parallelization~\cite{Tanenbaum2014}. Additionally important areas of computing such as image processing and machine learning lend themselves well to such parallelization. [citation needed, Phuong?] At the same time software as a service and the massive scale industry giants like Amazon require a complex network of distributed systems to provide their functionality robustly and efficiently~\cite{Amazon2015}.
\\\\
Hash tables are an important data structure for a variety of applications because they allow for data retrieval in constant time. Several lock-based hash tables for concurrent systems exist [citations], but the overhead of lock management and difficulty of resizing often make these impractical or inefficient~\cite{Shalev2006}. A lock free alternative is proposed by Shalev and Shavit in \cite{Shalev2006}. This approach has proven to be useful~\cite{lock-free-structures2013} and scale better with number of concurrent processes than lock-based approaches~\cite{Duarte-Haskell2016}.
\\\\
In both small- and large-scale computer systems it is important to ensure correctness. This is especially evident in critical infrastructure, but all scales and importance levels benefit from confidence in the correctness of their systems. [citation needed]
\\\\
It is therefore troublesome that such systems are incredibly difficult to design, debug and reason about. The complexity of interactions between processes and sheer number of possible edge cases makes it infeasible for a person to determine correctness.
\\\\
Early solutions to the problem of proving correctness include Hoare~\cite{Hoare1969}, Floyd~\cite{Floyd1967} and Pnueli's~\cite{Pnueli1977} temporal logics and Leslie Lamport's Temporal Logic of Actions (TLA)~\cite{Lamport1977} which seek to formalize the execution of programs in order to reason about them with logic. These formal methods proved useful, but laborious~\cite{Clarke2009}.
\\\\
Building on the work in temporal logics, model checkers seek to minimize the human labor and ingenuity needed to prove correctness. This is done by specifying a model using some system of logic and then letting a model checker exhaustively survey the possible states of the system. This automates the process of proving correctness. One such model checker is the TLC model checker based on Lamport's TLA and incorporated in the TLA+ IDE.

\section{Problem Statement}\label{sec:problem-statement}
In this project we work with TLA+ and the TLC model checker to specify a novel concurrent hashmap structure due to Shalev et al.~\cite{Shalev2006}. The goal is to prove the following problem statement:
\begin{quote}
    Shalev et al.'s split-ordered list design is a correct extensible hashmap for concurrent systems.
\end{quote}
Specifically we intend to show that a TLA+ specification displays the invariants Shalev et al. claim for their structure using the TLC model checker. In demonstrating this we will also explore and discuss the use of formal verification for concurrent data structures.

\section{Method}
In order to demonstrate the correctness of the hashmap, we specify its behavior using TLA+~\cite{Lamport_specifying_2002} and use the TLC model checker in the TLA+ toolbox~\cite{TLAplus} to test the claimed invariants.
\\\\
We construct four specifications:
\begin{enumerate}
    \item a generic hashmap,
    \item a non-concurrent specification of the split-order structure,
    \item a concurrent specification of the split-order structure, and
    \item a concurrent specification with operation ID's.
\end{enumerate}
The first two are used to test the behavior of the structure in a non-concurrent setting which allows for a larger state space. The third is used to test a smaller state space in a concurrent setting, while the final specification is needed to test invariants relating to early termination of operations.

\section{Scope}
Showing the correctness of Shalev et al.'s hashmap structure requires two things:
\begin{itemize}[label={}]
    \item that the specification of the structure is correct and
    \item that the behavior of the model checker is correct.
\end{itemize}
The latter is outside the scope of this project, but the TLC model checker is open source~\cite{TLAplus} and has been used in industry with success~\cite{Amazon2015, Lamport-Batson2002}.\\\\
On the other hand, the specification is very much within the scope of this project. For a specification to be helpful in proving correctness of a system it is important that it specifies the system accurately, and that the properties checked by the model checker are precisely the properties we wish to show in the system. This is achieved through an explanation of the specification in \autoref{ch:specification} and the results are discussed in \autoref{ch:concluding-remarks}.

\section{Outline}
\begin{enumerate}[label={}]
    \item \textbf{\Autoref{ch:background}} discusses the motivation for formal verification and model checking, followed by a description of Temporal Logic in \autoref{sec:TL} and the TLA+ language in \autoref{sec:TLA+}. Finally Shalev et al.'s hashmap design is described in \autoref{sec:hashmap}.
    \item \textbf{\Autoref{ch:specification}} describes the specification of the hashmap in TLA+ and the development of this specification.
    \item \textbf{\Autoref{ch:results}} describes the method and results of model checking.
    \item \textbf{\Autoref{ch:concluding-remarks}} discusses these results in relation to the problem statement, and explores experiences and lessons lerned.
\end{enumerate}


\chapter{Background}\label{ch:background}
This section presents relevant prior work and background on model checking, TLA+ and Shalev et al.'s hashmap structure. \Autoref{sec:model-checking} briefly describes the development and use of formal verification and model checkers, \autoref{sec:TL} recounts Pnueli's~\cite{Pnueli1977} early work on temporal logic, and \autoref{sec:TLA+} covers the syntax and structure of TLA+. Finally \autoref{sec:hashmap} describes Shalev et al.'s data structure.

\section{Model Checking}\label{sec:model-checking}
\paragraph{Model Checking: Algorithmic Verification and Debugging~\cite{Clarke2009}}
In the Turing Lecture by the winners of the 2007 Turing Award, Edmund Clarke, Allen Emerson and Joseph Sifakis they describe the develpment and use of model checkers as a verification method for computer systems. Previous efforts to prove correctness had been focused on formal proofs which have three key shortcomings:
\begin{enumerate}
    \item they require human ingenuity,
    \item they are difficult to work with in concurrent and distributed systems,
    \item they scale poorly with system size and complexity.
\end{enumerate}
Instead, they propose algorithmic model checkers.
\\\\
With this method a Temporal Logic is used to specify the correct behavior of a system and the model checker verifies that this behavior is not violated by exploring the state space of the model. Importantly, such model checkers produce a counter example -- an example of incorrect behavior -- which makes debugging and correcting the system easier.
Key properties of a temporal logic are \textit{expressiveness} and \textit{efficiency}.
\\\\
Model checking also scales poorly with system complexity, so several techniques are introduced to deal with "state space explosion"
\begin{itemize}
    \item symbolic checking of ordered binary decision diagrams
    \item isolation of independent events in concurrent systems
    \item bounded checking by solving SAT
    \item reduce state space by increasing level of abstraction
    \begin{itemize}
        \item if counterexamples are found a lower abstraction level is needed, but "good" properties hold through abstraction mappings
    \end{itemize}
\end{itemize}


\paragraph{How Amazon Web Services Uses Formal Methods~\cite{Amazon2015}}
Amazon's AWS services are all underpinned by large and complex distributed systems. This is necessary for high availability, growth and cost-effective infrastructure. Traditionally these systems have been tested by savvy engineers who know what to test and look for. However, some errors are very rare and will very likely slip through such testing. To catch these errors they employ model checking (with TLA+).
\\\\
The PlusCal or TLA+ specifications work as a tool to bridge the gap between design and implementation. Designs are expressive, but inprecise while the implementation is precise, but hides overall structure. Through a choice of abstraction level, specifications can bridge this gap and provide both. An expressive specification also provides useful documentation of the system.
\\\\
The key benefits of model checkers at Amazon are:
\begin{itemize}
    \item a precisely specified design helps make changes and optimizations safely. This usage improves system understanding.
    \item they are faster than formal proofs
    \item a correct design and the understanding the specs provide promote better, more correct code.
\end{itemize}

\section{Temporal Logics}\label{sec:TL}
\paragraph{The Temporal Logic of Programs ~\cite{Pnueli1977}}
In The Temporal Logic of Programs~\cite{Pnueli1977}, Amir Pnueli proposes a unified approach to the verification of both sequential and concurrent programs. His work seeks to unify approaches to to both, while also presenting a system that emulates the design intuition of programmers. The key concepts in this work are \textit{invariance} -- which covers partial correctness, clean behavior, mutual exlusion and deadlock freedom -- and \textit{eventuality} -- which generalizes these notions to cyclic programs and provides a special case of total correctness.
\\\\
A dynamic discrete system is generalized as a three-tuple $\langle S, R, s_0 \rangle$ where $S$ is the set of possible states, $R$ a transition relation, and $s_0$ the initial state of the system. In order to make later constructions easier we further specify
$$s = \langle \pi, u \rangle$$ where $\pi$ is the control component specifying the location in the program and $u$ is the data component describing the state of any variables and data structures, and
$$R(\pi, u) = N(\pi, u) \land T(\pi, u)$$ where $N$ describes the control flow and T the change in data such that a step in the execution may be described by
$$R(\langle \pi, u \rangle , \langle \pi', u' \rangle) \iff \pi' = N(\pi, u) \land u' = T(\pi, u)$$
To reason about concurrent programs we let states have multiple control components $s = \langle \pi_1, \pi_2,...,\pi_n, u \rangle$ and randomly choose one control component to update in each step. Finally we let $X$ be the set of all reachable states for the system. A predicate $p(s)$ is \textbf{invariant} if $p(s)$ is true $\forall s \in X$.
\\\\
We can now start to define useful properties of the systems described in this way.
\begin{itemize}[label={}]
    \item \textbf{Partial correctness} is the claim that given the correct input, a program produces the correct output. We let $\phi(x)$ be the statement "reaching the end state $\implies$ (correct input $\implies$ correct output)". Partial correctness is equivalent to saying $\phi$ is an invariant.
    \item \textbf{Clean execution} means the program does not behave illegally, i.e it does not access illegal memory locations or divide by zero. We may define these restrictions as a predicate to make clean execution equivalent to this predicate being invariant.
    \item \textbf{Mutual exclusion}. Given a critical section $C$, mutual exclusion of the processes $\pi_1$ and $\pi_2$ is described by the invariance of the predicate $\lnot(\pi_1 \in C \land \pi_2 \in C)$.
\end{itemize}
In addition to these properties we wish to reason about \textit{temporal} implications. We let time be described by a $t \in \N$ and $H(p,t)$ denote the value of the predicate $p$ at time $t$.
We then introduce the temporal operator $p \eventually q$ to mean $p$ eventually leads to $q$, or formally:
$$p \eventually q: \forall t_1 \exists t_2\ s.t\ t_1 \le t_2,  H(p, t_1) \implies H(q, t_2)$$
For all times $t_1$ there is a later time $t_2$ such that if $p$ holds at $t_1$, $q$ will hold at $t_2$.
Armed with eventuality we can define temporally useful properties of systems.
\begin{itemize}[label={}]
    \item \textbf{Total correctness} is stronger than partial correctness because it also requires that the program reaches an end state. We can express total correctness as $\langle \pi = l_0, u = \phi\rangle \eventually \langle \pi = l_m, u = \psi\rangle$ where $\phi$ denotes correct input, and $\psi$ denotes correct output and $l_0$, $l_m$ are the start and end labeles of the system, respectively.
    \item \textbf{Accessibility} is the guarantee that some segment $S$ of a program can be reached. It can be expressed by $\pi = l_0 \eventually \pi \in S$
    \item \textbf{Responsiveness}. It is often desirable that some request $r$ will be met by a response $s$. We call this responsiveness and describe it by $r \eventually s$.
\end{itemize}

With these definitions under our belt, Pnueli defines the necessary axioms and inference rules to reason about the correctness of programs.

\begin{figure}[h!]
    \begin{equation}\tag{A1}\label{axiom:1}
        [\forall s, s' p(s) \land R(s,s') \implies q(s')] \Rightarrow p \eventually q
    \end{equation}
    \begin{equation}\tag{A2}\label{axiom:2}
        (p \implies q) \Rightarrow p \eventually q
    \end{equation}
\caption{Pnueli's axioms}
\end{figure}

These axioms define two ways to establish eventuality. \ref{axiom:2} says that any logical implication is also an eventuality. \ref{axiom:1} is a little more involved, but states that if for all consecutive states $p$ being true in the first implies $q$ being true in the second, then $p$ eventually leads to $q$.

\begin{figure}[h]
    \begin{equation}\tag{R1}\label{rules:1}
        p \eventually q, \forall s, s' r(s) \land R(s,s') \implies r(s') \Rightarrow (p \land r) \eventually (q \land r)
    \end{equation}
    \begin{equation}\tag{R2}\label{rules:2}
        p \eventually q, q \eventually r \Rightarrow p \eventually r
    \end{equation}
    \begin{equation}\tag{R3}\label{rules:3}
        p_1 \eventually q, p_2 \eventually q \Rightarrow (p_1 \lor p_2) \eventually q
    \end{equation}
    \begin{equation}\tag{R4}\label{rules:4}
        p \eventually q \Rightarrow (\exists u p) \eventually q
    \end{equation}
\caption{Pnueli's inference rules}
\end{figure}

Using these axioms and inference rules as well as first-order logic, Pnueli goes on to formalize invariance and eventuality for sequential programs and concurrent programs.

\begin{itemize}[label={}]
    \item \textbf{Invariance} of the predicate $q(\pi, u)$ is described by the conjunction $\bigwedge\limits_{i}{\pi=l_i \implies q(l_i, u)}$, asserting that $q$ is true at all points of execution. This method is called an \textit{attachment} of the predicate to the program.
    \newpage{}
    In a concurrent program we generalize $q$ to hold when any $\pi_i$ is updated by $N$ and construct either a full attachment
    $$\bigwedge\limits_{i_1, i_2,...,i_n}{(\pi_1 = i_1 \land \pi_2 = i_2 \land ... \land \pi_n = i_n) \implies q(\pi_1,..,\pi_n,u)}$$ shown here for $n$ concurrent execution threads,
    or the partial attachment
    $$\bigwedge\limits_{i}{\pi_1=i \implies q(\pi_1 = i, \pi_2, u)} \land \bigwedge\limits_{j}{\pi_2=j \implies q(\pi_1, \pi_2 = j, u)}$$ shown here for two threads $\pi_1$ and $\pi_2$.
    \item \textbf{Eventuality} is formulated as the temporal implication $\pi = l_1 \land p(u) \eventually \pi=l_2 \land q(u)$. We can then describe the path between $l_1$ and $l_2$ by a finite sequence of steps and apply \ref{axiom:1} to each step.
\end{itemize}

Finally, Pnueli introduces two new "tense operators" \textbf{F}uture and \textbf{G}lobal on predicates such that at some time $n$
$$F(p) = \exists t \geq n \; s.t\; H(t,p)$$
$$G(p) = \forall t \geq n \; H(t,p)$$
This lets us describe useful properties such as
\begin{itemize}[label={}]
    \item $p \implies F(q)$ -- if $p$ is true now, then at some point in the future $q$ will be true.
    \item $G(p \implies F(q))$ -- whenever $p$ is true it will eventually be followed by a state in which $q$ is true. (this is equivalent to $p \eventually q$)     
\end{itemize}

\section{TLA+}\label{sec:TLA+}
This section introduces the structure and syntax of TLA+ necessary to follow the description of specifications in the following chapter.
\\\\
TLA+ is a formal specification language that describes a series of \textbf{actions} acting on \textbf{variables}. Each action statement is a logical predicate on a pair of states and a behavior adheres to a specification if this predicate holds for every step of the behavior.
\\\\
The basic form of a specification is
\begin{tla}
    Spec == Init /\ [][Next]_<<iterator, reverseIterator>>
\end{tla}
\begin{tlatex}
 \@x{\@s{16.4} Spec \.{\defeq} Init \.{\land} {\Box} [ Next ]_{ {\langle}
 iterator ,\, reverseIterator {\rangle}}}%
\end{tlatex}
\\\\
which reads "Init and always Next" and means the statement \textit{Init} is true for the initial state and the values of the variables \textit{iterator} and \textit{reverseIterator} make the statement \textit{Next} true on all steps.
\\\\
Each action is a predicate on primed and un-primed variables, where primed variables denote the value of a variable in the second state. For example
\begin{tla}
    Next == iterator' = iterator + 1 /\ UNCHANGED reverseIterator
\end{tla}
\begin{tlatex}
 \@x{\@s{16.4} Next \.{\defeq} iterator \.{'} \.{=} iterator \.{+} 1 \.{\land}
 {\UNCHANGED} reverseIterator}%
\end{tlatex}
\\\\
describes a variable \textit{iterator} which is increased by one in each step. This is not an assignment, but a logical predicate whose value can be true or false on each step. $=$ is a statement of mathematical equality, so the order of variables does not matter. Also note that each action must include all variables, so UNCHANGED is used to specify that the value of \textit{reverseIterator} does not change in this step.
\\\\
When an action includes multiple variables, their behavior can be specified by a conjunction or disjunction of predicates. For example
\begin{tla}
    Next ==
        /\ iterator' = iterator + 1
        /\ reverseIterator' = reverseIterator - 1
\end{tla}
\begin{tlatex}
\@x{\@s{16.4} Next \.{\defeq}}%
\@x{\@s{32.8} \.{\land} iterator \.{'} \.{=} iterator \.{+} 1}%
\@x{\@s{32.8} \.{\land} reverseIterator \.{'} \.{=} reverseIterator \.{-} 1}%
\end{tlatex}
\\\\
is a conjunction describing a step in which \textit{iterator} is increased by one and \textit{reverseIterator} is decreased by one, while
\begin{tla}
    Next ==
        \/ iterator' = iterator + 1
        \/ reverseIterator' = reverseIterator - 1
\end{tla}
\begin{tlatex}
\@x{\@s{16.4} Next \.{\defeq}}%
\@x{\@s{32.8} \.{\lor} iterator \.{'} \.{=} iterator \.{+} 1}%
\@x{\@s{32.8} \.{\lor} reverseIterator \.{'} \.{=} reverseIterator \.{-} 1}%
\end{tlatex}
\\\\
is a disjunction in which either \textit{iterator} is incremented or \textit{reverseIterator} is decremented.
\\\\
The values of variables can be simple constants like numbers and strings, sets, or functions from one set to another. Functions are used to represent associative arrays and more complicated structures.
\begin{tla}
    list == [0..42 |-> Nat]
\end{tla}
\begin{tlatex}
\@x{\@s{16.4} list \.{\defeq} [ 0 \.{\dotdot} 42 \.{\mapsto} Nat ]}%
\end{tlatex}
\\\\
Specifies a list with indexes from 0 to 42 (inclusive) and values in the natural numbers and
\begin{tla}
    student == [ID : 0..1000, major : {"CS", "math", "gardening"}]
\end{tla}
\begin{tlatex}
 \@x{\@s{16.4} student \.{\defeq} [ ID \.{:} 0 \.{\dotdot} 1000 ,\, major
 \.{:} \{\@w{CS} ,\,\@w{math} ,\,\@w{gardening} \} ]}%
\end{tlatex}
\\\\
describes a structure with two fields: \textit{ID} and \textit{major} and the possible values of these fields. The values of functions are updated with the EXCEPT construct where 
\begin{tla}
    list' = [list EXCEPT ![6] = 28]
\end{tla}
\begin{tlatex}
\@x{\@s{16.4} list \.{'} \.{=} [ list {\EXCEPT} {\bang} [ 6 ] \.{=} 28 ]}%
\end{tlatex}
\\\\
means that the new value list is the same as the old, except the value at index 6 is now 28. This notation is included because many readers find it strange or confusing.
\\\\
Additionally TLA+ includes the temporal operators $\Box$ and $\Diamond$ meaning always and eventually, which correspond to Pnueli's \textbf{G}lobal and \textbf{F}uture operators as well as $\Diamond\Box$ which means the predicate eventually becomes true and then stays true forever.
\\\\
Finally, implementation in TLA+ is implication. If specification A implements specification B this is exactly equivalent to $A \implies B$. If A is true on a behavior, then B is also true on that behavior.

\section{Split-Ordered List Hashmap}\label{sec:hashmap}
This section provides a description of Shalev et al.'s split-order hashmap structure~\cite{Shalev2006} -- the first lock-free extensible hash table implemented using only loads, stores and atomic Compare and Swap (CAS).
\\\\
Hashmaps are a key building block in many important systems [citation needed], but are difficult to implement concurrently. In particular, the resizing (extending) of the table is difficult to do atomically because at the very least a node must be moved from one list to another. In order to avoid conflicts and loss of data in this process some overhead is required which impacts performance.
\\\\
The key insight of Shalev et al. is to flip the process upside down. Instead of moving nodes between buckets, they suggest moving the buckets among a statically ordered list of nodes. This requires an ordering of the list in which a bucket can always be split into two new buckets while their contents remain correct. A node should always reside in the bucket corresponding to its key $\bmod{2^i}$ where $2^i$ is the current size of the table.

\paragraph{Split-Ordered Lists}
are introduced to make resizing of the map possible without introducing locks. By sorting the keys according to their reversed binary representation Shalev et al. obtain a list which can be always be split into buckets $\bmod{2^i}$. This is because such an ordering corresponds to difference in the keys' $i$th least significant bit, which is equivalent to having a different remainder $\bmod{2^i}$.
\\\\
To deal with the problems caused by removing nodes pointed to by hash table entries dummy nodes with the bucket value are introduced. These nodes signify the start of a bucket and are recursively initialized when an item is inserted into an unitialized bucket. To distinguish dummy nodes from regular nodes in the list, regular node keys have their most significant bit set to 1 before being reversed. This order and the structure of the map can be seen in \autoref{fig:split-order}.
\\\\
Insertion in to the map is done through atomic CAS instructions on the list. If a bucket is not initialized, a dummy node is created and inserted into the list before the new value is added as shown in \autoref{fig:simple-insert}. The map is expanded by doubling the number of buckets and inserting new dummy nodes. Because of the split-ordering of the list, it is always possible to insert a new bucket by splitting an existing one. This process is shown in \autoref{fig:insert-expand}.
\begin{figure}
    \includegraphics[width=\textwidth]{split-ordered-list-diagram.png}
\caption{The layout of the split-ordered list}
\label{fig:split-order}
\end{figure}

\begin{figure}
    \centering
    \subfloat[Initial state]{\includegraphics[width=.5\textwidth]{insert-0.png}}
    \subfloat[Dummy node is created]{\includegraphics[width=.5\textwidth]{insert-1.png}}
    \newline
    \subfloat[Dummy node is inserted in bucket]{\includegraphics[width=.5\textwidth]{insert-2.png}}
    \subfloat[New node is inserted]{\includegraphics[width=.5\textwidth]{insert-3.png}}
\caption{Insertion without bucket splitting}    
\label{fig:simple-insert}
\end{figure}

\begin{figure}
    \centering
    \subfloat[Initial state]{\includegraphics[height=2in]{expand-0.png}}
    \newline
    \subfloat[Table is expanded]{\includegraphics[height=2in]{expand-1.png}}
    \newline
    \subfloat[Dummy node for new bucket inserted]{\includegraphics[height=2in]{expand-2.png}}
    \newline
    \subfloat[Table entry points to bucket node]{\includegraphics[height=2in]{expand-3.png}}
\caption{Expansion and bucket splitting}    
\label{fig:insert-expand}
\end{figure}


\chapter{Specification}\label{ch:specification}
%intro
% structure of this chapter, structure of the spec, scope
This chapter describes the structure of the TLA+ specification and the process of writing the specification. First we introduce the goals and scope of the specification, then describe the definitions of necessary data structures and operations.
\\\\
The specification consists of two main parts:
\begin{enumerate}
    \item a generic hashmap and
    \item SplitOrder \textit{implementing} this map.
\end{enumerate}
The generic specification describes the workings of a hashmap with insert and remove operations and ensures that this structure behaves as specified. The SplitOrder specification describes Shalev et al.'s specific structure and algorithms for implementing hashmap functionality.
\\\\
We present two versions of the specification at two levels of granularity. The first assumes the atomicity of hashmap operations, while the second describes entirely concurrent operations.

\section{Goal}\label{sec:spec-goals}
The purpose of our specification is to verify the claims about correctness made by Shalev et al. Because TLA+ is designed for checking liveness and safety properties~\cite{Lund2019} we will not check claims about the performance of the implementation. This leaves 4 invariants:
\begin{enumerate}
    \item the list beginning at bucket 0 is always sorted
    \item if a bucket is initialized, then it points to a dummy node which is in the list beginning at bucket 0
    \item if a key $k$ is in the map, then \texttt{insert(k)} fails. Otherwise $k$ is added to the map
    \item if a key $k$ is in the map, then \texttt{remove(k)} removes it from the map. Otherwise it fails.
\end{enumerate}
The non-concurrent specification demonstrates correctness by implementing a generic hashmap specification which describes corerct behavior, while the concurrent specification looks directly at the above invariants.
Additionally we will check \textit{type safety}: at every point of execution, all keys and values are members of predefined key- and value-sets, respectively.

\section{Non-Concurrent Specification}
\subsection{Hashmap for Implementation}
\begin{figure}
    \begin{tla}
------------------------------ MODULE hashmap ------------------------------
(*****************************************************************************)
(*This module describes a hashmap to be used for testing with Shalev et al.'s*)
(*split-ordered list implementation of the data structure                    *)
(*****************************************************************************)

EXTENDS Integers

CONSTANTS NULL, PossibleKeys, PossibleValues

VARIABLES keys, map


(*******************************************************)
(*Initial state has empty map and no keys              *)
(*******************************************************)

HashmapInit ==  /\ keys = {}
                /\ map = [k \in PossibleKeys |-> NULL]

(*******************************************************)
(*Insert changes exactly one mapping of the hashmap    *)
(*and adds one key to the set of keys                  *)
(*******************************************************)
Insert ==   \exists k \in PossibleKeys :
                \exists v \in PossibleValues :
                    /\ keys' = keys \union {k}
                    /\ map' = [map EXCEPT ![k] = v]

(*******************************************************)
(*Remove sets exactly one mapping to NULL              *)
(*******************************************************)
Remove ==   \exists k \in PossibleKeys :
                /\ keys' = keys \ {k}
                /\ map' = [map EXCEPT ![k] = NULL]

(*******************************************************)
(*Next is either an insert, a remove or a find         *)
(*Find(k) returns NULL if not in map, otherwise a value*)
(*******************************************************)          
HashmapNext ==  \/ Insert
                \/ Remove


(*******************************************************)
(*TypeOK asserts all keys and values are of the right type*)
(*******************************************************) 
TypeOK ==   \forall k \in keys :
                /\ k \in PossibleKeys
                /\ map[k] \in PossibleValues

(*******************************************************)
(*KeyHasValue asserts that every key is mapped to a value*)
(*******************************************************) 
KeyHasValue == \forall k \in keys : ~(map[k] = NULL)

(*******************************************************)
(*The hashmap specification as a temporal formula      *)
(*******************************************************) 
HashmapSpec == HashmapInit /\ [][HashmapNext]_<<keys, map>>
=============================================================================
\end{tla}
\begin{tlatex}
\@x{}\moduleLeftDash\@xx{ {\MODULE} hashmap}\moduleRightDash\@xx{}%
\begin{lcom}{0}%
\begin{cpar}{0}{F}{F}{0}{0}{}%
This module describes a hashmap to be used for testing with Shalev et al.'s
 split-ordered list implementation of the data structure                    
\end{cpar}%
\end{lcom}%
\@pvspace{8.0pt}%
\@x{ {\EXTENDS} Integers}%
\@pvspace{8.0pt}%
\@x{ {\CONSTANTS} NULL ,\, PossibleKeys ,\, PossibleValues}%
\@pvspace{8.0pt}%
\@x{ {\VARIABLES} keys ,\, map}%
\@pvspace{16.0pt}%
\begin{lcom}{0}%
\begin{cpar}{0}{F}{F}{0}{0}{}%
Initial state has empty map and no keys              
\end{cpar}%
\end{lcom}%
\@pvspace{8.0pt}%
\@x{ HashmapInit \.{\defeq}\@s{4.1} \.{\land} keys \.{=} \{ \}}%
\@x{\@s{4.1} \.{\land} map \.{=} [ k \.{\in} PossibleKeys \.{\mapsto} NULL ]}%
\@pvspace{8.0pt}%
\begin{lcom}{0}%
\begin{cpar}{0}{F}{F}{0}{0}{}%
Insert changes exactly one mapping of the hashmap    
 and adds one key to the set of keys                  
\end{cpar}%
\end{lcom}%
\@x{ Insert \.{\defeq}\@s{8.2} \exists\, k \.{\in} PossibleKeys \.{:}}%
\@x{\@s{24.59} \exists\, v \.{\in} PossibleValues \.{:}}%
\@x{\@s{41.0} \.{\land} keys \.{'} \.{=} keys \.{\cup} \{ k \}}%
 \@x{\@s{41.0} \.{\land} map \.{'} \.{=} [ map {\EXCEPT} {\bang} [ k ] \.{=} v
 ]}%
\@pvspace{8.0pt}%
\begin{lcom}{0}%
\begin{cpar}{0}{F}{F}{0}{0}{}%
Remove sets exactly one mapping to NULL              
\end{cpar}%
\end{lcom}%
\@x{ Remove \.{\defeq}\@s{8.2} \exists\, k \.{\in} PossibleKeys \.{:}}%
\@x{\@s{24.59} \.{\land} keys \.{'} \.{=} keys \.{\,\backslash\,} \{ k \}}%
 \@x{\@s{24.59} \.{\land} map \.{'} \.{=} [ map {\EXCEPT} {\bang} [ k ] \.{=}
 NULL ]}%
\@pvspace{8.0pt}%
\begin{lcom}{0}%
\begin{cpar}{0}{F}{F}{0}{0}{}%
Next is either an insert, a remove or a find         
 Find(k) returns NULL if not in map, otherwise a value
\end{cpar}%
\end{lcom}%
\@x{ HashmapNext \.{\defeq}\@s{4.1} \.{\lor} Insert}%
\@x{\@s{4.1} \.{\lor} Remove}%
\@pvspace{16.0pt}%
\begin{lcom}{0}%
\begin{cpar}{0}{F}{F}{0}{0}{}%
TypeOK asserts all keys and values are of the right type
\end{cpar}%
\end{lcom}%
\@x{ TypeOK \.{\defeq}\@s{8.2} \forall\, k \.{\in} keys \.{:}}%
\@x{\@s{24.59} \.{\land} k \.{\in} PossibleKeys}%
\@x{\@s{24.59} \.{\land} map [ k ] \.{\in} PossibleValues}%
\@pvspace{8.0pt}%
\begin{lcom}{0}%
\begin{cpar}{0}{F}{F}{0}{0}{}%
KeyHasValue asserts that every key is mapped to a value
\end{cpar}%
\end{lcom}%
 \@x{ KeyHasValue \.{\defeq} \forall\, k \.{\in} keys \.{:} {\lnot} ( map [ k
 ] \.{=} NULL )}%
\@pvspace{8.0pt}%
\begin{lcom}{0}%
\begin{cpar}{0}{F}{F}{0}{0}{}%
The hashmap specification as a temporal formula      
\end{cpar}%
\end{lcom}%
 \@x{ HashmapSpec \.{\defeq} HashmapInit \.{\land} {\Box} [ HashmapNext ]_{
 {\langle} keys ,\, map {\rangle}}}%
\@x{}\bottombar\@xx{}%
\end{tlatex}
    \caption{The hashmap specification}
    \label{fig:hashmap-spec}
\end{figure}
The generic hashmap specification seen in \autoref{fig:hashmap-spec} describes how a hashmap \textit{should} behave. It maintains a set of keys \textit{keys} and a mapping \textit{map} from keys to values. Additionally it describes two operations: insert and remove.
\\\\
Insert adds a key to the set of keys and changes one entry in the map. The key is added with a set union, which preserves key uniqueness. Updating the map uses the \texttt{EXCEPT} construct, to say "the map is the same except the new key maps to the new value". The insert action is always enabled since there will always be keys and values in PossibleKeys and PossibleValues.
\\\\
Remove removes one key from the set and changes its mapping to NULL. This is done through the set difference operator and the same \texttt{EXCEPT} construct as in insert. Both operations are idempotent, so attempting to remove a key that is not in the map will result in no change.
\\\\
The specification also contains temporal formulae \textit{TypeOK} and \textit{KeyHasValue} that specify correct behavior. These have been checked with the TLC model checker and holds for up to 16 possible values and 4 possible keys.
\\\\
Finally the entire hashmap is described by \textit{HashmapSpec}. This temporal formula states that the hashmap specification is fulfilled if the initial state fulfills \textit{HashmapInit} and each action fulfills \textit{HashmapNext}. This formula is used to prove a more complex specification implements the semantics of Hashmap.

\subsection{Non-Concurrent Specification}\label{subsec:non-concurrent}
The specification consists of three main parts:
\begin{enumerate}
    \item \label{SpecList:structures} the data structures,
    \item \label{SpecList:operations} operations on the map, and
    \item \label{SpecList:spec} the abstract specification tying them together.
\end{enumerate}
This section describes the construction and function of each in turn.
\begin{figure}
    \begin{tla}
EXTENDS Integers

CONSTANTS NULL, PossibleKeys, PossibleValues, LoadFactor, MaxSize

VARIABLES keys, AuxKeys, list, buckets, size, count, map

ASSUME
    /\ PossibleKeys \subseteq 0..15
    /\ NULL \notin PossibleKeys
    /\ NULL \notin PossibleValues

(****************************************************)
(*The Init for split-order                          *)
(*keys is initially empty                           *)
(*the map maps every possible key to NULL           *)
(*The list initially contains only the 0 dummy node *)
(****************************************************)
SOInit ==   /\ keys = {}
            /\ AuxKeys = {}
            /\ list = [n \in 0..255 |-> IF n = 0 THEN SODummyKey(0) ELSE NULL]
            /\ buckets = [m \in PossibleKeys |-> IF m = 0 THEN SODummyKey(0) ELSE NULL]
            /\ size = 1
            /\ count = 0
            /\ map = [k \in PossibleKeys |-> NULL]

\end{tla}
\begin{tlatex}
\@x{ {\EXTENDS} Integers}%
\@pvspace{8.0pt}%
 \@x{ {\CONSTANTS} NULL ,\, PossibleKeys ,\, PossibleValues ,\, LoadFactor ,\,
 MaxSize}%
\@pvspace{8.0pt}%
 \@x{ {\VARIABLES} keys ,\, AuxKeys ,\, list ,\, buckets ,\, size ,\, count
 ,\, map}%
\@pvspace{8.0pt}%
\@x{ {\ASSUME}}%
\@x{\@s{16.4} \.{\land} PossibleKeys \.{\subseteq} 0 \.{\dotdot} 15}%
\@x{\@s{16.4} \.{\land} NULL \.{\notin} PossibleKeys}%
\@x{\@s{16.4} \.{\land} NULL \.{\notin} PossibleValues}%
\@pvspace{8.0pt}%
\begin{lcom}{0}%
\begin{cpar}{0}{F}{F}{0}{0}{}%
The Init for split-order                          
 keys is initially empty                           
 the map maps every possible key to NULL           
 The list initially contains only the 0 dummy node 
\end{cpar}%
\end{lcom}%
\@x{ SOInit \.{\defeq}\@s{8.2} \.{\land} keys \.{=} \{ \}}%
\@x{\@s{8.2} \.{\land} AuxKeys \.{=} \{ \}}%
 \@x{\@s{8.2} \.{\land} list \.{=} [ n \.{\in} 0 \.{\dotdot} 255 \.{\mapsto}
 {\IF} n \.{=} 0 \.{\THEN} SODummyKey ( 0 ) \.{\ELSE} NULL ]}%
 \@x{\@s{8.2} \.{\land} buckets \.{=} [ m \.{\in} PossibleKeys \.{\mapsto}
 {\IF} m \.{=} 0 \.{\THEN} SODummyKey ( 0 ) \.{\ELSE} NULL ]}%
\@x{\@s{8.2} \.{\land} size \.{=} 1}%
\@x{\@s{8.2} \.{\land} count \.{=} 0}%
\@x{\@s{8.2} \.{\land} map \.{=} [ k \.{\in} PossibleKeys \.{\mapsto} NULL ]}%
\@pvspace{8.0pt}%
\end{tlatex}
\caption{The initial state of the specification}
\label{fig:SO-init}
\end{figure}
\\\\
The necessary data structures are a list of nodes and an array of buckets pointing to nodes. These are both specified as TLA+ functions. The list is a function from the set of list-keys to the set of values, while bucekts is a function from keys to list-keys. Additionally the specification includes a set of keys and a map from keys to values that correspond to the keys and map in the generic specification. The initial state of the map, showing these structures and their initial values is shown in \autoref{fig:SO-init}

\begin{figure}
\begin{tla}
SOInsert == /\  \E k \in PossibleKeys :
                \E v \in PossibleValues :
                    BucketInsert(k, v)

BucketInsert(k, v) ==
(*Either a bucket needs to be initialized*)
    \/  /\ buckets[k % size] = NULL
        /\ BucketInit(k % size)
        /\ ListInsert(SORegularKey(k), v)
        /\ AuxKeys' = AuxKeys \union {k}                      
    (*Or the bucket is already initialized*)
    \/  /\ buckets[k % size] /= NULL
        /\ ListInsert(SORegularKey(k), v)
        /\ AuxKeys' = AuxKeys \union {k}
        /\ UNCHANGED <<buckets>>

ListInsert(k, v) == IF list[k] = NULL
                THEN list' = [list EXCEPT ![k] = v] /\ count' = count + 1
                ELSE UNCHANGED <<list, count>>

\end{tla} 
\begin{tlatex}
\@x{ SOInsert \.{\defeq} \.{\land}\@s{4.1} \E\, k \.{\in} PossibleKeys \.{:}}%
\@x{\@s{4.1} \E\, v \.{\in} PossibleValues \.{:}}%
\@x{\@s{8.2} BucketInsert ( k ,\, v )}%
\@pvspace{8.0pt}%
\@x{ BucketInsert ( k ,\, v ) \.{\defeq}}%
\@x{}%
\@y{%
 Either a bucket needs to be initialized
}%
\@xx{}%
 \@x{\@s{16.4} \.{\lor}\@s{4.1} \.{\land} buckets [ k \.{\%} size ] \.{=}
 NULL}%
\@x{\@s{20.5} \.{\land} BucketInit ( k \.{\%} size )}%
\@x{\@s{20.5} \.{\land} ListInsert ( SORegularKey ( k ) ,\, v )}%
\@x{\@s{20.5} \.{\land} AuxKeys \.{'} \.{=} AuxKeys \.{\cup} \{ k \}}%
\@x{\@s{16.4}}%
\@y{%
 Or the bucket is already initialized
}%
\@xx{}%
 \@x{\@s{16.4} \.{\lor}\@s{4.1} \.{\land} buckets [ k \.{\%} size ] \.{\neq}
 NULL}%
\@x{\@s{20.5} \.{\land} ListInsert ( SORegularKey ( k ) ,\, v )}%
\@x{\@s{20.5} \.{\land} AuxKeys \.{'} \.{=} AuxKeys \.{\cup} \{ k \}}%
\@x{\@s{20.5} \.{\land} {\UNCHANGED} {\langle} buckets {\rangle}}%
\@pvspace{8.0pt}%
\@x{ ListInsert ( k ,\, v ) \.{\defeq} {\IF} list [ k ] \.{=} NULL}%
 \@x{\@s{4.1} \.{\THEN} list \.{'} \.{=} [ list {\EXCEPT} {\bang} [ k ] \.{=}
 v ] \.{\land} count \.{'} \.{=} count \.{+} 1}%
\@x{\@s{4.1} \.{\ELSE} {\UNCHANGED} {\langle} list ,\, count {\rangle}}%
\@pvspace{8.0pt}%
\end{tlatex}
\caption{The \textit{Insert} operation}
\label{fig:SO-insert}
\end{figure}
\\\\
The \textit{Insert} and \textit{Remove} operations are written in three layers. \autoref{fig:SO-insert} shows the Insert operation. First, \textit{SOInsert} describes a very high-level view: there exists some key and some value, and we insert the value with that key. \textit{BucketInsert} is the most involved, corresponding to the insert operation described by Shalev et al.'s pseudocode~\cite{Shalev2006}. Here the correct bucket is found or initialized and the value is inserted into the list pointed to by this bucket with the split-order key. FInally, \textit{ListInsert} inserts the value into the list, or ignores it if the node already has a value.

\begin{figure}
    \begin{tla}
        SONext ==   \/ SOInsert /\ BucketGrow /\ UNCHANGED <<map, keys>>
            \/ SORemove /\ UNCHANGED <<size, map, keys>>
            \/ SOFind   /\ UNCHANGED <<size, count, list>>
    \end{tla}
\begin{tlatex}
 \@x{\@s{32.8} SONext \.{\defeq}\@s{8.2} \.{\lor} SOInsert \.{\land}
 BucketGrow \.{\land} {\UNCHANGED} {\langle} map ,\, keys {\rangle}}%
 \@x{\@s{49.19} \.{\lor} SORemove \.{\land} {\UNCHANGED} {\langle} size ,\,
 map ,\, keys {\rangle}}%
 \@x{\@s{49.19} \.{\lor} SOFind \.{\land} {\UNCHANGED} {\langle} size ,\,
 count ,\, list {\rangle}}%
\end{tlatex}
    \caption{The Next action}
    \label{fig:SO-next}
\end{figure}
\\\\
Finally, the \textit{Next} action shown in \autoref{fig:SO-next} describes the transition of the system from one state to another. It states that such a transition consists of either inserting and growing the map, removing, or the \textit{SOFind} operation.

\begin{figure}
    \begin{tla}
        SOFind == \E k \in AuxKeys :
                /\ keys' = keys \union {k}
                /\ AuxKeys' = AuxKeys \ {k}
                /\ IF buckets[k % size] = NULL
                     THEN /\ BucketInit(k % size)
                          /\ map' = [map EXCEPT ![k] = ListFind(k % size, SORegularKey(k))]
                     ELSE /\ UNCHANGED buckets
                          /\ map' = [map EXCEPT ![k] = ListFind(k % size, SORegularKey(k))]

    \end{tla}
\begin{tlatex}
\@x{\@s{32.8} SOFind \.{\defeq} \E\, k \.{\in} AuxKeys \.{:}}%
\@x{\@s{36.89} \.{\land} keys \.{'} \.{=} keys \.{\cup} \{ k \}}%
 \@x{\@s{36.89} \.{\land} AuxKeys \.{'} \.{=} AuxKeys \.{\,\backslash\,} \{ k
 \}}%
\@x{\@s{36.89} \.{\land} {\IF} buckets [ k \.{\%} size ] \.{=} NULL}%
\@x{\@s{45.1} \.{\THEN} \.{\land} BucketInit ( k \.{\%} size )}%
 \@x{\@s{45.1} \.{\land} map \.{'} \.{=} [ map {\EXCEPT} {\bang} [ k ] \.{=}
 ListFind ( k \.{\%} size ,\, SORegularKey ( k ) ) ]}%
\@x{\@s{45.1} \.{\ELSE} \.{\land} {\UNCHANGED} buckets}%
 \@x{\@s{45.1} \.{\land} map \.{'} \.{=} [ map {\EXCEPT} {\bang} [ k ] \.{=}
 ListFind ( k \.{\%} size ,\, SORegularKey ( k ) ) ]}%
\@pvspace{8.0pt}%
\end{tlatex}
    \caption{The \textit{SOFind} operation}
    \label{fig:SO-find}
\end{figure}
\begin{figure}
    \begin{tla}
    SOSpec == SOInit /\ [][SONext]_<<keys, AuxKeys, list, buckets, size, count, map>>

    INSTANCE hashmap

    THEOREM SOSpec => HashmapSpec
    \end{tla}
\begin{tlatex}
 \@x{\@s{16.4} SOSpec \.{\defeq} SOInit \.{\land} {\Box} [ SONext ]_{
 {\langle} keys ,\, AuxKeys ,\, list ,\, buckets ,\, size ,\, count ,\, map
 {\rangle}}}%
\@pvspace{8.0pt}%
\@x{\@s{16.4} {\INSTANCE} hashmap}%
\@pvspace{8.0pt}%
\@x{\@s{16.4} {\THEOREM} SOSpec \.{\implies} HashmapSpec}%
\end{tlatex}
    \caption{Implementation of generic hashmap}
    \label{fig:SO-implementation}
\end{figure}
\\\\
The \textit{SOFind} operation shown in \autoref{fig:SO-find} corresponds to the find operation in Shalev et al.'s pseudocode and is responsible for updating the map. Because we wish to show that this specification implements the generic hashmap it is necessary to update the set of keys and the map itself at the same time and so a set of auxiliary keys is maintained and only added to the "real" map once a find operation looks for them. Using the "working variables" trick, the specification can be shown to implement the generic hashmap through implication as seen in \autoref{fig:SO-implementation}.
\\\\
The theorem $SOSpec \Rightarrow HashmapSpec$ seen in \autoref{fig:SO-implementation} states that any program following the split-order specification also follows the hashmap specification. Hence, any program following the split-order specification is a correct implementation of a hashmap. It is tested by checking the property \textit{HashmapSpec} in a model checking SOSpec.

\subsection{Concurrent Specification}
\begin{figure}
    \begin{tla}
OperationStates ==
    (*Set of all possible active operations            *)
    (*They can be of type insert, delete or bucket\_init*)
    (*Step denotes the current step of the operation   *)
    [type: {"insert"}, step : 1..4, key : PossibleKeys, value : PossibleValues]
        \union 
    [type: {"delete"}, step : 1..3, key : PossibleKeys]
        \union 
    [type: {"bucket_init"}, step : 1..3, bucket : 0..(MaxSize-1)]
    \end{tla}
\begin{tlatex}
\@x{ OperationStates \.{\defeq}}%
\@x{\@s{16.4}}%
\@y{%
 Set of all possible active operations            
}%
\@xx{}%
\@x{\@s{16.4}}%
\@y{%
 They can be of type insert, delete or bucket\_init
}%
\@xx{}%
\@x{\@s{16.4}}%
\@y{%
 Step denotes the current step of the operation   
}%
\@xx{}%
 \@x{\@s{16.4} [ type \.{:} \{\@w{insert} \} ,\, step \.{:} 1 \.{\dotdot} 4
 ,\, key \.{:} PossibleKeys ,\, value \.{:} PossibleValues ]}%
\@x{\@s{28.69} \.{\cup}}%
 \@x{\@s{16.4} [ type \.{:} \{\@w{delete} \} ,\, step \.{:} 1 \.{\dotdot} 3
 ,\, key \.{:} PossibleKeys ]}%
\@x{\@s{28.69} \.{\cup}}%
 \@x{\@s{16.4} [ type \.{:} \{\@w{bucket\_init} \} ,\, step \.{:} 1
 \.{\dotdot} 3 ,\, bucket \.{:} 0 \.{\dotdot} ( MaxSize \.{-} 1 ) ]}%
\end{tlatex}
    \caption{The operation structures}
    \label{fig:op-structure}
\end{figure}

\begin{figure}
    \begin{tla}
        (*Begin an insert operation*)
        Insert(k, v) == activeOps' = activeOps (+) SetToBag({[type|-> "insert", step |-> 1, key |-> k, value |-> v]})
        (*Begin a delete operation*)
        Delete(k) == activeOps' = activeOps (+) SetToBag({[type|-> "delete", step |-> 1, key |-> k]})
        (*Begin a bucket_init operation*)
        BucketInit(b) == activeOps' = activeOps (+) SetToBag({[type|-> "bucket_init", step |-> 1, bucket |-> b]})
        
        NextStep(op) == activeOps' = (activeOps (-) SetToBag({op})) (+) SetToBag({[op EXCEPT !["step"] = op.step + 1]})
        End(op) == activeOps' = activeOps (-) SetToBag({op})
    \end{tla}
\begin{tlatex}
\@x{\@s{32.8}}%
\@y{%
 Begin an insert operation
}%
\@xx{}%
 \@x{\@s{32.8} Insert ( k ,\, v ) \.{\defeq} activeOps \.{'} \.{=} activeOps
 \.{\oplus} SetToBag ( \{ [ type \.{\mapsto}\@w{insert} ,\, step \.{\mapsto}
 1 ,\, key \.{\mapsto} k ,\, value \.{\mapsto} v ] \} )}%
\@x{\@s{32.8}}%
\@y{%
 Begin a delete operation
}%
\@xx{}%
 \@x{\@s{32.8} Delete ( k ) \.{\defeq} activeOps \.{'} \.{=} activeOps
 \.{\oplus} SetToBag ( \{ [ type \.{\mapsto}\@w{delete} ,\, step \.{\mapsto}
 1 ,\, key \.{\mapsto} k ] \} )}%
\@x{\@s{32.8}}%
\@y{%
 Begin a bucket_init operation
}%
\@xx{}%
 \@x{\@s{32.8} BucketInit ( b ) \.{\defeq} activeOps \.{'} \.{=} activeOps
 \.{\oplus} SetToBag ( \{ [ type \.{\mapsto}\@w{bucket\_init} ,\, step
 \.{\mapsto} 1 ,\, bucket \.{\mapsto} b ] \} )}%
\@pvspace{8.0pt}%
 \@x{\@s{32.8} NextStep ( op ) \.{\defeq} activeOps \.{'} \.{=} ( activeOps
 \.{\ominus} SetToBag ( \{ op \} ) ) \.{\oplus} SetToBag ( \{ [ op {\EXCEPT}
 {\bang} [\@w{step} ] \.{=} op . step \.{+} 1 ] \} )}%
 \@x{\@s{32.8} End ( op ) \.{\defeq} activeOps \.{'} \.{=} activeOps
 \.{\ominus} SetToBag ( \{ op \} )}%
\end{tlatex}
    \caption{Starting and stepping through operations}
    \label{fig:op-progress}
\end{figure}

\begin{figure}
    \begin{tla}
SONext ==
    \/  /\ \E k \in PossibleKeys :
             \E v \in PossibleValues :
                Insert(k, v)
        /\ BagCardinality(activeOps) < MaxActiveOps
        /\ UNCHANGED <<buckets, count, list, size>>
    \/  /\ \E k \in PossibleKeys :
            Delete(k)
        /\ BagCardinality(activeOps) < MaxActiveOps
        /\ UNCHANGED <<buckets, count, list, size>>
    \/ Insert1
    \/ Insert2
    \/ Insert3
    \/ Insert4
    \/ Delete1
    \/ Delete2
    \/ Delete3
    \/ BucketInit1
    \/ BucketInit2
    \/ BucketInit3
    \end{tla}
\begin{tlatex}
\@x{ SONext \.{\defeq}}%
\@x{\@s{16.4} \.{\lor}\@s{4.1} \.{\land} \E\, k \.{\in} PossibleKeys \.{:}}%
\@x{\@s{28.7} \E\, v \.{\in} PossibleValues \.{:}}%
\@x{\@s{28.7} Insert ( k ,\, v )}%
\@x{\@s{20.5} \.{\land} BagCardinality ( activeOps ) \.{<} MaxActiveOps}%
 \@x{\@s{20.5} \.{\land} {\UNCHANGED} {\langle} buckets ,\, count ,\, list ,\,
 size {\rangle}}%
\@x{\@s{16.4} \.{\lor}\@s{4.10} \.{\land} \E\, k \.{\in} PossibleKeys \.{:}}%
\@x{\@s{24.6} Delete ( k )}%
\@x{\@s{20.5} \.{\land} BagCardinality ( activeOps ) \.{<} MaxActiveOps}%
 \@x{\@s{20.5} \.{\land} {\UNCHANGED} {\langle} buckets ,\, count ,\, list ,\,
 size {\rangle}}%
\@x{\@s{16.4} \.{\lor} Insert1}%
\@x{\@s{16.4} \.{\lor} Insert2}%
\@x{\@s{16.4} \.{\lor} Insert3}%
\@x{\@s{16.4} \.{\lor} Insert4}%
\@x{\@s{16.4} \.{\lor} Delete1}%
\@x{\@s{16.4} \.{\lor} Delete2}%
\@x{\@s{16.4} \.{\lor} Delete3}%
\@x{\@s{16.4} \.{\lor} BucketInit1}%
\@x{\@s{16.4} \.{\lor} BucketInit2}%
\@x{\@s{16.4} \.{\lor} BucketInit3}%
\end{tlatex}
    \caption{The concurrent Next action}
    \label{fig:concurrent-next}
\end{figure}

\begin{figure}
    \begin{tla}
        (*Steps of a delete operation*)
        Delete1 ==
            (*Start a bucket_init if necessary*)
            \E  op \in BagToSet(activeOps) :
                /\ op.type = "delete"
                /\ op.step = 1
                /\ IF buckets[op.key % size] = NULL
                        THEN activeOps' = (activeOps (-) SetToBag({op}))
                                                (+) SetToBag({[op EXCEPT !["step"] = op.step + 1]})
                                                (+) SetToBag({[type|-> "bucket_init", step |-> 1, bucket |-> op.key % size]})
                        ELSE NextStep(op)
                /\ UNCHANGED <<list, buckets, size, count>>
        
        Delete2 ==
            (*If the key is not there, end operation. Else, remove it*)
            \E  op \in BagToSet(activeOps) :
                /\ op.type = "delete"
                /\ op.step = 2
                /\  IF list[SORegularKey(op.key)] = NULL
                        THEN /\ End(op)
                             /\ UNCHANGED list
                        ELSE /\ list' = [list EXCEPT ![SORegularKey(op.key)] = NULL]
                             /\ NextStep(op)
                /\ UNCHANGED <<buckets, size, count>>        
        
        Delete3 ==
            (*Decrement count*)
            \E  op \in BagToSet(activeOps) :
                /\ op.type = "delete"
                /\ op.step = 3
                /\ count' = count - 1
                /\ End(op)
                /\ UNCHANGED <<buckets, list, size>>
    \end{tla}
\begin{tlatex}
\@x{\@s{32.8}}%
\@y{%
 Steps of a delete operation
}%
\@xx{}%
\@x{\@s{32.8} Delete1 \.{\defeq}}%
\@x{\@s{49.19}}%
\@y{%
 Start a bucket_init if necessary
}%
\@xx{}%
\@x{\@s{49.19} \E\,\@s{4.1} op \.{\in} BagToSet ( activeOps ) \.{:}}%
\@x{\@s{53.29} \.{\land} op . type \.{=}\@w{delete}}%
\@x{\@s{53.29} \.{\land} op . step \.{=} 1}%
\@x{\@s{53.29} \.{\land} {\IF} buckets [ op . key \.{\%} size ] \.{=} NULL}%
 \@x{\@s{61.49} \.{\THEN} activeOps \.{'} \.{=} ( activeOps \.{\ominus}
 SetToBag ( \{ op \} ) )}%
 \@x{\@s{82.0} \.{\oplus} SetToBag ( \{ [ op {\EXCEPT} {\bang} [\@w{step} ]
 \.{=} op . step \.{+} 1 ] \} )}%
 \@x{\@s{82.0} \.{\oplus} SetToBag ( \{ [ type \.{\mapsto}\@w{bucket\_init}
 ,\, step \.{\mapsto} 1 ,\, bucket \.{\mapsto} op . key \.{\%} size ] \} )}%
\@x{\@s{61.49} \.{\ELSE} NextStep ( op )}%
 \@x{\@s{53.29} \.{\land} {\UNCHANGED} {\langle} list ,\, buckets ,\, size ,\,
 count {\rangle}}%
\@pvspace{8.0pt}%
\@x{\@s{32.8} Delete2 \.{\defeq}}%
\@x{\@s{49.19}}%
\@y{%
 If the key is not there, end operation. Else, remove it
}%
\@xx{}%
\@x{\@s{49.19} \E\,\@s{4.1} op \.{\in} BagToSet ( activeOps ) \.{:}}%
\@x{\@s{53.29} \.{\land} op . type \.{=}\@w{delete}}%
\@x{\@s{53.29} \.{\land} op . step \.{=} 2}%
 \@x{\@s{53.29} \.{\land}\@s{4.1} {\IF} list [ SORegularKey ( op . key ) ]
 \.{=} NULL}%
\@x{\@s{61.49} \.{\THEN} \.{\land} End ( op )}%
\@x{\@s{61.49} \.{\land} {\UNCHANGED} list}%
 \@x{\@s{61.49} \.{\ELSE} \.{\land} list \.{'} \.{=} [ list {\EXCEPT} {\bang}
 [ SORegularKey ( op . key ) ] \.{=} NULL ]}%
\@x{\@s{61.49} \.{\land} NextStep ( op )}%
 \@x{\@s{53.29} \.{\land} {\UNCHANGED} {\langle} buckets ,\, size ,\, count
 {\rangle}}%
\@pvspace{8.0pt}%
\@x{\@s{32.8} Delete3 \.{\defeq}}%
\@x{\@s{49.19}}%
\@y{%
 Decrement count
}%
\@xx{}%
\@x{\@s{49.19} \E\,\@s{4.1} op \.{\in} BagToSet ( activeOps ) \.{:}}%
\@x{\@s{53.29} \.{\land} op . type \.{=}\@w{delete}}%
\@x{\@s{53.29} \.{\land} op . step \.{=} 3}%
\@x{\@s{53.29} \.{\land} count \.{'} \.{=} count \.{-} 1}%
\@x{\@s{53.29} \.{\land} End ( op )}%
 \@x{\@s{53.29} \.{\land} {\UNCHANGED} {\langle} buckets ,\, list ,\, size
 {\rangle}}%
\end{tlatex}
    \caption{The steps of a \textit{Delete} operation}
    \label{fig:op-delete}
\end{figure}
The specification described in \autoref{subsec:non-concurrent} describes the working of the split-order structure. However, it is not useful for proving the correctness of the structure in a concurrent setting. This is because its structure presupposes the linearizability of its operations by making them action statements. This means each state transition consists of a complete operation, rather than a single instruction.
\\\\
To specify concurrent working, a more granular specification is needed. In a complete description each step would be a single machine instruction, but this is both infeasible and counterproductive as such a specification is no more useful for verification than the program itself.
\\\\
Instead, we identify the steps in the each operation that change the shared state of the system and make those the steps of our specification. This results in each operation (\textit{Insert, Remove}, and \textit{Bucket Init}) being split into several steps. We then maintain a multiset (called a "bag") of active operations of the form shown in \autoref{fig:op-structure} and step through them as shown in \autoref{fig:op-progress}. The result is the next-step action shown in \autoref{fig:concurrent-next}. This disjunction specifies that each next step can either start an insert or remove operation, or perform a single step in an active operation.
\\\\
To show the structure of a single operation in the concurrent specification, we will look at \textit{Delete} (\autoref{fig:op-delete}). \textit{Delete}1 checks if the relevant bucket is initialized and starts a bucket\_init operation if it is not. Because starting a new operation and advancing the current operation both modify the state of \textit{activeOps}, a union of both changes is needed. Also note that this step is enabled iff there exists an operation with type "delete" and step 1 in the set of active operations. \textit{Delete}2 removes a node from the list. This step is assumed to be atomic by our assumption that an atomic list implementation is available. Finally \textit{Delete}3 decrements count. Note that the previous step did not advance if a node was not removed, so the decrement step will always be taken if a delete operation has reached step 3.

\chapter{Results}\label{ch:results}
In this section we present the process and results of model checking the specification. First we describe the method of checking and the properties checked by the model. Then we present the quantitative results along with commentary on these results. \Autoref{sec:tech-details} covers the technical details of this process.

\section{Method}
To demonstrate the invariants claimed by Shalev et al.~\cite{Shalev2006} we use the TLC model checker to test the specifications outlined in \autoref{sec:spec-goals}. The first specification (\autoref{subsec:non-concurrent}) was tested by setting \textit{HashmapSpec} as a property of the model, thus showing that SplitOrder implements the generic hashmap specification.
\\\\
\textit{SOConcurrent} is more granular than the abstract specification which makes it difficult to demonstrate implementation. Instead the invariants were written as predicates in TLA such that they can be checked by the TLC model checker. The following paragraphs describe these invariants in turn.
\\\\
The first invariant states that the list beginning at bucket 0 is always sorted. Because our list is specified as a function from positions to values, this is trivialy true for the specification.
\\\\
The second invariant asserts that if a bucket is initialized, then it points to a dummy node in the list. This is captured by \textit{BucketsInitialized} (\autoref{fig:invariant2}) which asserts each bucket is either NULL, or points to an initialized node in the list. This is an invariant on a single state and can be checked straightforwardly.
\begin{figure}[h]
    \begin{tla}
        (*Each bucket is either unitialized or points to a node with the dummy key*)
        BucketsInitialized ==
            \A i \in 0..(size-1) :
                \/ buckets[i] = NULL
                \/ buckets[i] = SODummyKey(i) /\ list[SODummyKey(i)] = i
    \end{tla}
\begin{tlatex}
\@x{\@s{32.8}}%
\@y{%
 Each bucket is either unitialized or points to a node with the dummy key
}%
\@xx{}%
\@x{\@s{32.8} BucketsInitialized \.{\defeq}}%
\@x{\@s{49.19} \A\, i \.{\in} 0 \.{\dotdot} ( size \.{-} 1 ) \.{:}}%
\@x{\@s{53.29} \.{\lor} buckets [ i ] \.{=} NULL}%
 \@x{\@s{53.29} \.{\lor} buckets [ i ] \.{=} SODummyKey ( i ) \.{\land} list [
 SODummyKey ( i ) ] \.{=} i}%
\end{tlatex}
    \caption{Invariant 2 as a TLA predicate}
    \label{fig:invariant2}
\end{figure}
\\\\
Invariant 3 and 4 are both statements about a behavior, rather than a state. This makes them liveness properties and therefore more difficult to check. \Autoref{fig:invariants} shows half of each invariant, namely that \textit{Insert(k)} succeeds if $k$ is not present and \textit{Delete(k)} succeeds if $k$ is present. To do this they make use of the $\Diamond$ operator meaning "eventually" to claim "if an insert is initiated and the key is not in the map, then eventually the value will be inserted", and the opposite for \textit{Delete}. Also note that both properties are written in terms of the constant set of all possible operation states because TLC cannot check liveness properties which include existential qualifiers ($\E$ and $\A$) over variables.
\begin{figure}[h]
    \begin{tla}
(*An insert with key not in map will succeed*)
InsertSucceeds ==
    \A op \in OperationStates :
        IF op.type = "insert"
        (*This test is needed to avoid checking fields that do not exist in other types of operations*)
        THEN
            /\ op \in BagToSet(activeOps)
            /\ op.step = 1
            /\ list[SORegularKey(op.key)] = NULL
            => <>(list[SORegularKey(op.key)] = op.value)
        ELSE TRUE

(*A delete with key in map will succeed*)
DeleteSucceeds ==
    \A op \in OperationStates :
        IF op.type = "delete"
        THEN
            /\ op \in BagToSet(activeOps)
            /\ op.step = 1
            /\ list[SORegularKey(op.key)] /= NULL
        => <>(list[SORegularKey(op.key)] = NULL)
        ELSE TRUE
        
    \end{tla}
\begin{tlatex}
\@x{}%
\@y{%
 An insert with key not in map will succeed
}%
\@xx{}%
\@x{ InsertSucceeds \.{\defeq}}%
\@x{\@s{16.4} \A\, op \.{\in} OperationStates \.{:}}%
\@x{\@s{20.5} {\IF} op . type \.{=}\@w{insert}}%
\@x{\@s{20.5}}%
\@y{%
 This test is needed to avoid checking fields that do not exist in other
 types of operations
}%
\@xx{}%
\@x{\@s{20.5} \.{\THEN}}%
\@x{\@s{36.9} \.{\land} op \.{\in} BagToSet ( activeOps )}%
\@x{\@s{36.9} \.{\land} op . step \.{=} 1}%
\@x{\@s{36.9} \.{\land} list [ SORegularKey ( op . key ) ] \.{=} NULL}%
 \@x{\@s{36.9} \.{\implies} {\Diamond} ( list [ SORegularKey ( op . key ) ]
 \.{=} op . value )}%
\@x{\@s{20.5} \.{\ELSE} {\TRUE}}%
\@pvspace{8.0pt}%
\@x{}%
\@y{%
 A delete with key in map will succeed
}%
\@xx{}%
\@x{ DeleteSucceeds \.{\defeq}}%
\@x{\@s{16.4} \A\, op \.{\in} OperationStates \.{:}}%
\@x{\@s{20.5} {\IF} op . type \.{=}\@w{delete}}%
\@x{\@s{20.5} \.{\THEN}}%
\@x{\@s{36.9} \.{\land} op \.{\in} BagToSet ( activeOps )}%
\@x{\@s{36.9} \.{\land} op . step \.{=} 1}%
\@x{\@s{36.9} \.{\land} list [ SORegularKey ( op . key ) ] \.{\neq} NULL}%
 \@x{\@s{20.5} \.{\implies} {\Diamond} ( list [ SORegularKey ( op . key ) ]
 \.{=} NULL )}%
\@x{\@s{20.5} \.{\ELSE} {\TRUE}}%
\@pvspace{8.0pt}%
\end{tlatex}
    \caption{The claimed invariants as TLA predicates}
    \label{fig:invariants}
\end{figure}
\\\\
The second halves of invariant 3 and 4 (\autoref{fig:fail-invariants}) introduce another complication. To show that an operation fails, it is necessary to differentiate them, so that we can make claims about the failure of a specific operation. The differentiation is done by introducing an additional ID element in each operation. Additionally the properties make use of the $\Box$ operator meaning "always" to claim "if an insert operation is initiated and the key is already in the map, that operation never reaches step 3".
\begin{figure}[h]
    \begin{tla}
(*An insert with key in map will not reach step 3*)
InsertFails ==
    \A op \in OperationStates :
        IF op.type = "insert"
        THEN
            /\ op \in (activeOps)
            /\ op.step = 1
            /\ list[SORegularKey(op.key)] /= NULL
         => <>[](~([op EXCEPT !["step"] = 3] \in (activeOps)))
        ELSE TRUE

(*A delete with key not in map will not reach step 3*)
DeleteFails ==
    \A op \in OperationStates :
            IF op.type = "delete"
            THEN
                /\ op \in (activeOps)
                /\ op.step = 1
                /\ list[SORegularKey(op.key)] = NULL
            => <>[](~([op EXCEPT !["step"] = 3] \in (activeOps)))
            ELSE TRUE

OperationStates ==
(*Set of all possible active operations            *)
(*They can be of type insert, delete or bucket_init*)
(*Step denotes the current step of the operation   *)
[type: {"insert"}, step : 1..4, key : PossibleKeys, value : PossibleValues, id : 0..MaxID]
    \union 
[type: {"delete"}, step : 1..3, key : PossibleKeys, id : 0..MaxID]
    \union
[type: {"bucket_init"}, step : 1..3, bucket : 0..(MaxSize-1), id : 0..MaxID]
    \end{tla}
\begin{tlatex}
\@x{}%
\@y{%
 An insert with key in map will not reach step 3
}%
\@xx{}%
\@x{ InsertFails \.{\defeq}}%
\@x{\@s{16.4} \A\, op \.{\in} OperationStates \.{:}}%
\@x{\@s{20.5} {\IF} op . type \.{=}\@w{insert}}%
\@x{\@s{20.5} \.{\THEN}}%
\@x{\@s{36.9} \.{\land} op \.{\in} ( activeOps )}%
\@x{\@s{36.9} \.{\land} op . step \.{=} 1}%
\@x{\@s{36.9} \.{\land} list [ SORegularKey ( op . key ) ] \.{\neq} NULL}%
 \@x{\@s{24.6} \.{\implies}\@s{12.30} {\Diamond} {\Box} ( {\lnot} ( [ op
 {\EXCEPT} {\bang} [\@w{step} ] \.{=} 3 ] \.{\in} ( activeOps ) ) )}%
\@x{\@s{20.5} \.{\ELSE} {\TRUE}}%
\@pvspace{8.0pt}%
\@x{}%
\@y{%
 A delete with key not in map will not reach step 3
}%
\@xx{}%
\@x{ DeleteFails \.{\defeq}}%
\@x{\@s{16.4} \A\, op \.{\in} OperationStates \.{:}}%
\@x{\@s{24.59} {\IF} op . type \.{=}\@w{delete}}%
\@x{\@s{24.59} \.{\THEN}}%
\@x{\@s{41.0} \.{\land} op \.{\in} ( activeOps )}%
\@x{\@s{41.0} \.{\land} op . step \.{=} 1}%
\@x{\@s{41.0} \.{\land} list [ SORegularKey ( op . key ) ] \.{=} NULL}%
 \@x{\@s{24.59} \.{\implies} {\Diamond} {\Box} ( {\lnot} ( [ op {\EXCEPT}
 {\bang} [\@w{step} ] \.{=} 3 ] \.{\in} ( activeOps ) ) )}%
\@x{\@s{24.59} \.{\ELSE} {\TRUE}}%
\@pvspace{8.0pt}%
\@x{ OperationStates \.{\defeq}}%
\@x{}%
\@y{%
 Set of all possible active operations            
}%
\@xx{}%
\@x{}%
\@y{%
 They can be of type insert, delete or bucket_init
}%
\@xx{}%
\@x{}%
\@y{%
 Step denotes the current step of the operation   
}%
\@xx{}%
 \@x{ [ type \.{:} \{\@w{insert} \} ,\, step \.{:} 1 \.{\dotdot} 4 ,\, key
 \.{:} PossibleKeys ,\, value \.{:} PossibleValues ,\, id \.{:} 0 \.{\dotdot}
 MaxID ]}%
\@x{\@s{12.29} \.{\cup}}%
 \@x{ [ type \.{:} \{\@w{delete} \} ,\, step \.{:} 1 \.{\dotdot} 3 ,\, key
 \.{:} PossibleKeys ,\, id \.{:} 0 \.{\dotdot} MaxID ]}%
\@x{\@s{12.29} \.{\cup}}%
 \@x{ [ type \.{:} \{\@w{bucket\_init} \} ,\, step \.{:} 1 \.{\dotdot} 3 ,\,
 bucket \.{:} 0 \.{\dotdot} ( MaxSize \.{-} 1 ) ,\, id \.{:} 0 \.{\dotdot}
 MaxID ]}%
\end{tlatex}
\caption{The failure invariants as TLA predicates}
\label{fig:fail-invariants}
\end{figure}
\\\\
Having formalized these invariants we are left with one safety property and four liveness properties, as well as the non-concurrent specification.

\section{Technical Details}\label{sec:tech-details}
Tests were run with version 2.15 of the TLC model checker on a Intel(R) Core i5-8250U CPU with 8~GiB of memory and 250~GiB of hard drive space running Ubuntu 18.04. TLC was set to use 8 worker threads and 6~GiB of memory.
\\\\
Unless otherwise noted, the maximum size of the map was equal to the number of possible keys and the load factor was set to half of the maximum size.

\section{Quantitative Analysis}
This section covers the results of model checking for three different specifications. Firstly the coarse non-concurrent specification and then the concurrent specification with and without operation IDs.

\subsection{Non-concurrent specification}
By setting \textit{HashmapSpec} as a property while checking \textit{SplitOrder}, the model checker tests if the latter implements the former. The implementation was checked for increasing sizes of the map, with results reported in \autoref{tab:SplitOrder}.
\begin{table}[h]
    \centering
    \begin{tabular}{ |c|c||c|c|c| }
        \hline
        Keys & Values & Diameter & Distinct & Time \\
        &        &          & States   & (hh:mm:ss)\\
        \hline
        2 & 4  & 10 & 2,523      & 00:00:01\\
        2 & 8  & 10 & 23,763     & 00:00:08\\
        2 & 16 & 10 & 279,075    & 00:01:02\\
        4 & 2  & 17 & 39,827     & 00:00:09\\
        4 & 4  & 17 & 1,790,067  & 00:03:44\\
        4 & 8  & 17 & 147,266,723& 07:14:45\\
        \hline
    \end{tabular}
    \caption{Model checking results for SplitOrder}
    \label{tab:SplitOrder}
\end{table}
While the results of \textit{SplitOrder} do not prove much about the structure in a concurrent setting, showing this implementation holds -- at least for maps with up to 4 keys and 8 values -- helps to increase our confidence that is does in fact implement an abstract hashmap structure.
\\\\
It is also noteworthy that even this relatively simple specification ran out of hard-drive space (using roughly 150~GB) trying to test a map with 4 possible keys and 16 possible values.

\subsection{Concurrent Specification}
In the concurrent specification each invariant was checked in isolation, again increasing the size of the state space incrementally.
\begin{table}[h]
    \centering
    \resizebox{\textwidth}{!}{%        
    \begin{tabular}{ |L|c|c|c||c|c|c| }
        \hline
        Invariant & Keys & Values & Conc. & Diameter & Distinct & Time\\
        &      &        & Ops        &          & States   & (mm:ss)\\
        \hline
        \textit{InsertSucceeds} & 2 & 2 & 2 & 38 & 10,083    & 00:02\\
        & 2 & 4 & 2 & 38 & 66,901    & 00:13\\
        & 2 & 4 & 3 & 45 & 1,351,453 & 01:50\\
        & 4 & 2 & 2 & 62 & 1,627,390 & 02:15\\
        \hline
        \textit{DeleteSucceeds} & 2 & 2 & 2 & 38 & 10,083    & 00:01\\
        & 2 & 4 & 2 & 38 & 66,901    & 00:07\\
        & 2 & 4 & 3 & 45 & 1,351,453 & 00:31\\
        & 4 & 2 & 2 & 62 & 1,627,390 & 00:45\\
        \hline
        \textit{BucketsInitialized} & 2 & 2 & 2 & 38 & 10,083    & 00:02\\
        & 2 & 4 & 2 & 38 & 66,901    & 00:16\\
        & 2 & 4 & 8 & 38 & 624,645   & 00:16\\
        & 2 & 4 & 16& 38 & 7,371,157 & 01:55\\
        & 4 & 2 & 2 & 62 & 1,627,390 & 00:22\\
        & 4 & 3 & 2 & 62 & 8,368,282 & 01:39\\
        & 4 & 4 & 2 & 62 & 29,973,646& 06:10\\
        & 4 & 5 & 2 & 62 & 85,419,916& 18:41\\
        & 4 & 2 & 3 & 75 & 61,353,460& 13:59\\
        \hline
    \end{tabular}}
    \caption{TLC model checking results for SOConcurrent}
    \label{tab:SOConcurrent}
\end{table}
\begin{table}
    \centering
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{ |L|L|c|c|c||c|c|c|p{1cm}| }
        \hline
        Invariant & Keys & Values & Conc. & Diameter & Distinct & Time & Error\\
                  &      &        & Ops   &          & States   & (hh:mm:ss)&\\
        \hline
        Non-Concurrent   &4      & 16     &       &17 & 84,587,043 & 02:54:11 & 3\\
        \hline
        \textit{InsertSucceeds}& 4 & 3 & 2 & 27 & 1,426,888 & 00:33:30 & 2\\
        \hline
        \textit{DeleteSucceds}& 4 & 3 & 2 & 39 & 6,067,795 & 00:30:30 & 1\\
        \hline
        \textit{BucketsInitialized}& 4 & 2 & 4 & 57 &120,175,837& 00:26:49 &4\\
        \hline
    \end{tabular}}
    \caption{Failed model checks}
    \label{tab:failed-checks}
\end{table}
\begin{table}
    \centering
    \begin{tabular}{ |L|L| }
        \hline
        Code & Error\\
        \hline
        1 & GC Overhead limit exceeded\\
        2 & Out of heap space\\
        3 & No space left on device\\
        4 & Unknown\\
        \hline
    \end{tabular}
    \caption{Error Codes}
    \label{tab:errors}
\end{table}
\\
\Autoref{tab:SOConcurrent} shows the results of checking \textit{InsertSucceeds} and \textit{DeleteSucceeds}. Both exhaust the available memory attempting to check a map with 4 possible keys and 3 possible values in approximately 30 minutes. However, both hold for a smaller map with only 2 possible values and this completed in only a few minutes. Also note that \textit{DeleteSucceeds} runs out of memory having explored all most 5 times the number of unique states. The descrepancy in space explored is likely because an insert operaeration takes 4 steps, while a delete takes only 3 leading to shorter behavior traces for deletes.
\\\\
\Autoref{tab:SOConcurrent} also shows the result of checking \textit{BucketsInitialized} on the same specification. Since \textit{BucektsInitialized} is a safety property, memory is not consumed as quickly as with the earlier liveness properties and \textit{BucektsInitialized} was shown to hold for up to 4 keys and 5 values. Additionally this property was checked for larger numbers of concurrent operations. Note that a map with 4 keys and 2 values was fully explored for 2 concurrent operations in 22 seconds, but took 14 minutes with 3 concurrent operations. 4 concurrent operations forced a reboot after 26 minutes.
\\\\
\Autoref{tab:failed-checks} and \ref{tab:errors} describe model checking runs which failed to complete due to memory or disk space constraints.
%Notes
%\begin{itemize}
    %        \item state space explosion from 2 to 3 values is immense
    %        \item BucketsInitialized with 4 concurrent ops crashed my laptop
    %        \item Final InsertSucceeds spent 2/3 of the time on diameter 27
    %        \item Memory runs out later with DeleteSucceeds, probably because delete takes fewer steps so traces are shorter
    %        \item smaller tests have same diameter and state number, which is expected (good)
    %        \item DeleteSucceeds triggers GC fault instead of out-of-memory. Might mean less of the memory is reclaimable?
    %\end{itemize}
\begin{table}
    \centering
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{ |L|c|c|c||c|c|c|p{1cm}| }
        \hline
        Invariant & Keys & Values & Conc. & Diameter & Distinct & Time      & Error\\
                  &      &        & Ops   &          & States   & (hh:mm:ss)&\\
        \hline
        \textit{BucketsInitialized} & 2 & 2 & 2 & 406 & 59,272,902 & 00:07:08 &\\
        & 2 & 4 & 2 & 406 & 387,645,300& 00:54:33 &\\
        & 4 & 2 & 2 & 153 & 665,993,030& 04:22:12 &\\
        \hline
        \textit{InsertFails} & 2 & 2 & 2 & >20 & >64,000  & >00:01:07 & 2\\
        \hline
        \textit{DeleteFails} & 2 & 2 & 2 & >25 & >153,370& >00:02:12 & 1\\ 
        \hline
    \end{tabular}}
    \caption{Model checking SOConcurrent with operation IDs}
    \label{tab:SOConcurrent_ID}
\end{table}
\\\\
For the final two invariants it was necessary to use a slightly different specification in which operations are associated with an ID. Because previous model resulted in a diameter of 62, this model was set up to use a maximum of 62 unique IDs. Differentiating between individual operations leads to a significant increase in both diameter and distinct states because equivalent sets of active operations are now seen as distinct states.
\\\\
\Autoref{tab:SOConcurrent_ID} shows the results of checking this model with operation IDs. The dpeth of the state space even for minimal key/value sets makes it infeasible to check liveness properties for this specification.

% \\\\
% Lessons learned
% \begin{itemize}
%     \item state space explosion is \textbf{real}
%     \item liveness properties tend to quickly exceed Java's GC limit
% \end{itemize}

\chapter{Concluding Remarks}\label{ch:concluding-remarks}
In this chapter we first discuss the results of model checking in relation to the problem statement, then follows a discussion of the experience of writing and testing the specification, and the lessons learned in this process. Finally we conclude our work and answer the problem statement.


\section{The Results of Model Checking}
The results of model-checking the non-concurrent specification show that it does implement the higher level abstract specification. While it does not show the correctness of the structure in a concurrent setting, this result gives us reason to believe the overall structure is sound if the operations are linearizable.
\\\\
The concurrent model shows similarly promising results for all but the \textit{InsertFails} and \textit{DeleteFails} properties. Due to memory constraints, the model could not be used to check very large state spaces, but the positive results on small subsets give some credence to the correctness of the hashmap.
\\\\
In the case of \textit{InsertFails} and \textit{DeleteFails} the need to differentiate individual operations lead to an explosion in the size of the state space so large it became impossible to check these properties. In particular the diameter is a problem because they are both liveness properties and so require storing the very long execution trace.
\\\\
One issue with model checking specifications as a way to prove the correctness of programs is the correctness of the model checking. The problem is two-fold: how certain can we be that the model checker does its job correctly; and how certain can we be that the specification is really specifying what we want it to?
\\\\
The final specification behaves as expected along several axes. Type correctness holds across all the tested invariants (though it was not checked along with liveness properties to reduce computational load), the size of the bucket array and the set of active operations both stay within bounds, and additional possible values increases the number of unique states without increasing the depth of the state space while an increase in the number of possible keys increases the depth.
\\\\
A surprising feature is the sheer size of the state space. Even for two possible keys and two possible values, the state space of the concurrent specification is surprisingly large (10,083 unique states). One way to evaluate the specification would be a calculation of the expected state space of the system with the same parameters. If such a calculation agreed with the results of model checking it would increase our confidence in the specification accurately describing the system.
\\\\
% The conclusion-y part
The results of model checking do not conclusively prove correctness because they must necessarily be finite in scope. In the case where limited computing power and memory is available, they are definitely finite and indeed quite small. One could argue that correctness on a small sample space implies total correctness, but such an argument can not be based on model checking alone. Again, some human ingenuity is needed. However, successful model checking on a small sample space should increase our confidence in the correctness of the structure.
\\\\
Model checking with TLC can be used to exhaustively show the correctness of a structure on a small subset of the sample space. The results on this subset correspond to the properties formally proven by Shalev et al. with the exception of operation failures which proved impossible to check with the computational resources available.

\section{Lessons Learned}
% I learned a lot, but the output does not prove anything about concurrent correctness
% structure of the spec follows the structure of the implementation, which does not lend itself to logical state transitions.
% should have made a more conscious decision about step size
% "correct" thinking: what constitutes the state? when does that change?
% implementation (the proof kind) looked to be elegant, but introduced unwanted complexity
In this section we will explain some of the choices made in the development of the specification and discuss the experiences and lessons learned from the process. We present three specific lessons from this project along with concrete experiences and possible solutions.
\\\\
% plan:
%   - move the implementation paragraph to the end and rewrite
%   - rewrite non-concurrent specification critique to clearly articulate the problem and relate to lesson 1.
%   - number the other two lessons
%   - maybe number infinities and mis-stated properties?
The three specific lessons:
\begin{enumerate}[label=\textbf{\arabic*}.]
    \item decide on the purpose of the specification as early as possible
    \item test assumed invariants and try to break them
    \item choose step size early and deliberately
\end{enumerate}

\paragraph{1.}
It is useful to clearly decide on the purpose of the specification as early as possible. On several occasions we discovered that the specification was not suitable for its purpose. First, the non-concurrent spec proved difficult to map to an abstract hashmap spec. Then, the concurrent spec turned out to be unsuitable for showing the failure of operations because it did not differentiate between individual operations and so could not show that a specific operation was aborted. In both cases it would have been useful to be clear about precisely what we wished to show at an earlier state and plan the specification accordingly.
\\\\
The clearest example of this error was our attempt to show the correct behavior of a non-concurrent specification through implementation. The idealized hashmap specification proved impossible to directly map to the SplitOrder specification because such a mapping would involve a \textit{find} operation which may result in a bucket having to be initialized and this sort of two-level action is not permitted in refinement mappings in TLA+. Instead we introduced a set of auxillary variables~\cite{Lamport2019a} which maintain an idealized map that is updated in atomic steps. While auxillary variables are a possible solution, they introduced additional complexity and made it more difficult to see that the specification accurately describes the structure.
\\\\
Additionally this initial non-concurrent specification was not well suited to showing the precise invariants claimed by Shalev et al. and was difficult to adapt to a concurrent version. Because the structure of the specification was modeled after pseudocode, and therefore divided into presumed linearizable functions, adapting it to describe a concurrent setting required a full rewrite.
\\\\
Finally, neither specification was well suited to showing failure invariants: the claim that certain operations would always abort. In the non-concurrent case this was because each operation was a single action and so could not abort at all, and in the concurrent case it was because an operation was not distinguishable from a later operation with the same arguments. While the concurrent specification was relatively easy to expand with operation IDs, it was still unable to demonstrate these properties due to state space explosion. It is possible that a specification that was designed from the beginning with these properties in mind would have been better suited to demonstrate them.
\paragraph{2.} %make these into specific examples of it being useful to assert properties and scrap that last little paragraph. also the set-> multiset transition
A useful tool when writing specifications in TLA+ is making and testing assumptions. If you think something is true about the specification, the assumption can be written as a property or invariant and checked using the model checker. Both positive results -- when invariants believed to be true hold, or invariants believed to be false are shown to be false -- and negative results -- when invariants believed to hold are violated -- can be extremely useful. It is also useful to purposefully attempt to violate assumptions by changing the specification.
\\\\
One such case occured in early testing of the \textit{DeleteFails} and \textit{InsertFails} properties. An early attempt was tautologically true because it described operations terminating at \textbf{some} later stage, which was true whether the operation aborted or completed. This error was discovered by removing the terminating clause from the specification and observing that the property still appeared to hold. False positives like this error are very difficult to find without making changes to the specification and attempting to violate assumptions.
\\\\
Another error occured with an early version of the concurrent specification. Because the active operations were kept in a set, there could never be two identical operations active at the same time. In practice this meant one operation would "disappear" if another identical operation was initiated. The error was discovered because it lead to an ever increasing \textit{count} when \textit{Delete} operations disappeared. By checking the invariant $count \; \leq \; 4$ on a model with only four possible values, an error trace showing this error was obtained. As a result, the specification was changed to use a multiset (Bag) to allow for multiple copies of the same operation.
\paragraph{3.}%be clearer about what "step size" means and how it was done
Finally, it is advicable to decide on the "step size" of the specification as early as possible.~\cite{Lamport_video_2019}. By step size we mean roughly the number of variables that change in each action. For the concurrent specification this was done by identifying the variables that constitute the state of the map: the list, the buckets, size, and count; and then making each change to one of these a single step. Making this choice deliberately and clearly made it much easier to write the concurrent specification than the non-concurrent one where no such considerations were made.
\\\\
The choice of step size carries with it assumptions of atomicity. By allowing \textit{list} and \textit{size} to change in one action we assume that elements can be inserted and removed from the list and that an integer can be fetched and incremented atomically.
\\\\
In this section we have described three concrete lessons learned from the project that are applicable to future work on specifications in TLA+. These were motivated by concrete experiences during the project.

\section{The Usefulness of Formal Specification}
Finally, a note on the usefulness of writing and model checking specifications: Sometimes formal specification can uncover rare or complex errors in algorithms and protocols~\cite{Lund2019, Zave2012}, but in this case it did not. Instead, our result may slightly increase confidence in the correctness of Shalev et al.'s hashmap, but arguably no more than a working implementation passing tests. That increase is a poor return on investment, especially if the user has to learn the tools.
\\\\
It seems that formal specification and model checking has two uses:
\begin{enumerate}
    \item as a way to produce minimal examples of a suspected error, and \label{point:error}
    \item as a development tool for algorithms and protocols \label{point:dev}
\end{enumerate}
The first case is useful because it lets developers find and show errors in the algorithms, rather than in programs or implementations. In the second case, a specification is used to test and improve an algorithm or protocol under development without resorting to implementation. This is especially useful when an implementation requires hardware~\cite{Lamport-Batson2002} or is prohibitively large in scale~\cite{Amazon2015} and lets developers iterate on designs while ensuring their correctness in a similar way to test-driven development for implementation.
\section{Conclusion}
In this project a formal specification of Shalev et al.'s lock free hashmap implementation has been written in TLA+ and the TLC model checker has been used to demonstrate their claimed invariants on state spaces with up to 4 keys, 16 possible values and 3 concurrent processes.
\\\\
We recall the problem statement from \autoref{sec:problem-statement}:
\begin{quotation}
    Shalev et al.'s split-ordered list design is a correct extensible hashmap for concurrent systems.
\end{quotation}
The results of model checking confirmed the claimed invariants of Shalev et al.'s design for maps with up to four keys and two possible values, with the exception of failure conditions for \textit{Delete} and \textit{Insert}. The testing was limited by the memory required to test liveness properties.
\\\\
Additionally the use of formal specification in TLA+ and the TLC model checker were discussed and three lessons were formulated based on concrete experiences during the process.
\\\\
We conclude that model checking gives increased confidence in the correctness of Shalev et al.'s split-order hashmap, but that it is poorly suited to showing liveness properties in the absence of significant memory resources.
\\\\
Finally, we note that model checking may have more value as a development tool for protocols, data structures and algorithms than as a way to prove correctness of existing programs.
\backmatter
\phantomsection
\addcontentsline{toc}{chapter}{Bibliography}
\printbibliography{}
\end{document}

