\documentclass{uit-thesis}

\usepackage{enumitem}
\usepackage[backend=biber, sorting=none]{biblatex}
\addbibresource{sources.bib}
\graphicspath{{./figures/}}

\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\renewcommand{\implies}{\rightarrow}
\newcommand{\eventually}{\rightsquigarrow}

\begin{document}

\title{Formal Verification of a Lock-free Split-order Hashmap}
% \subtitle{Subtitle}% Note: this is optional, and may be commented out
\author{Åsmund Aqissiaq Arild Kløvstad}
\thesisfaculty{Faculty of Science and Technology \\ Department of Computer Science}
\thesisprogramme{INF-2990 Bachelor's thesis in Informatics \today{}}

\maketitle

\frontmatter

\begin{epigraph}
\epigraphitem{You don't need to understand everything at once. You understand one thing, then you pat yourself on the back, have a cup of coffee, and understand one more thing.}{Nada Amin}
\end{epigraph}

\tableofcontents

\mainmatter

\chapter{Introduction}
Concurrent and distributed systems are extremely important in modern software development. Due to the difficulty of developing ever smaller and more powerful CPUs the trend in hardware design since about 2005 has been to increase the number of cores to allow for high levels of parallelization\cite{Tanenbaum2014}. Additionally important areas of computing such as image processing and machine learning lend themselves well to such parallelization. [citation needed, Phuong?] At the same time software as a service and the massive scale industry giants like Amazon require a complex network of distributed systems to provide their functionality robustly and efficiently\cite{Amazon2015}.
\\\\
Hash tables are an important data structure for a variety of applications because they allow for data retrieval in constant time. Several lock-based hash tables for concurrent systems exist [citations], but the overhead of lock management and difficulty of resizing often make these impractical or inefficient\cite{Shalev2006}. A lock free alternative is proposed by Shalev and Shavit in \cite{Shalev2006}. This approach has proven to be useful\cite{lock-free-structures2013} and scale better than lock-based approaches\cite{Duarte-Haskell2016}.
\\\\
In both small- and large-scale computer systems it is important to ensure correctness. This is especially evident in critical infrastructure, but all scales and importance levels benefit from confidence in the correctness of their systems. [citation needed]
\\\\
It is therefore troublesome that such systems are incredibly difficult to design, debug and reason about. The complexity of interactions between processes and sheer number of possible edge cases makes it infeasible for a person to determine correctness.
\\\\
Early solutions to this problem include Hoare\cite{Hoare1969}, Floyd\cite{Floyd1967} and Pnueli's\cite{Pnueli1977} temporal logics and Leslie Lamport's Temporal Logic of Actions\cite{Lamport1977} which seek to formalize the execution of programs in order to reason about them with logic. These formal methods proved useful, but laborious\cite{Clarke2009}.
\\\\
Building on the work in temporal logics, model checkers seek to minimize the human labor and ingenuity needed to prove correctness. This is done by specifying a model using some system of logic and then letting a model checker exhaustively survey the possible states of the system. This automates the process of proving correctness. One such model checker is the TLC model checker based on Lamport's TLA and incorporated in the TLA+ IDE.

\section{Thesis}
Shalev et al.'s split-ordered list design is a correct extensible hashmap for concurrent systems.
\\\\
Furthermore it is possible to check this using a formal model checker, and the results of this will correspond to the properties proven by Shalev et al.

\section{Method}
In order to prove the correctness of the hashmap, its behavior will be implemented as a specification in TLA+\cite{Lamport_specifying_2002} and the TLC model checker will be used to test the claimed invariants.
\\\\
The specification will be developed in stages of increasing granularity, assuming the atomicity of operations to begin with and gradually loosening assumptions.

\section{Scope?}

\section{Outline}
\begin{enumerate}[label={}]
    \item \textbf{\Autoref{ch:background}} discusses the motivation for formal verification and model checking, followed by a description of Temporal Logic in \autoref{sec:TL} and the TLA+ language in \autoref{sec:TLA+}. Finally Shalev et al.'s hashmap design is described in \autoref{sec:hashmap}.
    \item \textbf{\Autoref{ch:specification}} describes the specification of the hashmap in TLA+ and the development of this specification.
    \item Finally \textbf{\autoref{ch:results}} describes the results of model checking and discusses these in relation to our thesis in \autoref{sec:discussion}. 
\end{enumerate}


\chapter{Background}\label{ch:background}
\paragraph{Model Checking: Algorithmic Verification and Debugging\cite{Clarke2009}}
In the Turing Lecture by the winners of the 2007 Turing Award, Edmund Clarke, Allen Emerson and Joseph Sifakis they describe the develpment and use of model checkers as a verification method for computer systems. Previous efforts to prove correctness had been focused on formal proofs which have three key shortcomings:
\begin{enumerate}
    \item they require human ingenuity,
    \item they are difficult to work with in concurrent and distributed systems,
    \item they scale poorly with system size and complexity.
\end{enumerate}
Instead, they propose algorithmic model checkers.
\\\\
With this method a Temporal Logic is used to specify the correct behavior of a system and the model checker verifies that this behavior is not violated by exploring the state space of the model. Importantly, such model checkers produce a counter example -- an example of incorrect behavior -- which makes debugging and correcting the system easier.
Key properties of a temporal logic are \textit{expressiveness} and \textit{efficiency}.
\\\\
Model checking also scales poorly with system complexity, so several techniques are introduced to deal with "state space explosion"
\begin{itemize}
    \item symbolic checking of ordered binary decision diagrams
    \item isolation of independent events in concurrent systems
    \item bounded checking by solving SAT
    \item reduce state space by increasing level of abstraction
    \begin{itemize}
        \item if counterexamples are found a lower abstraction level is needed, but "good" properties hold through abstraction mappings
    \end{itemize}
\end{itemize}


\paragraph{How Amazon Web Services Uses Formal Methods\cite{Amazon2015}}
Amazon's AWS services are all underpinned by large and complex distributed systems. This is necessary for high availability, growth and cost-effective infrastructure. Traditionally these systems have been tested by savvy engineers who know what to test and look for. However, some errors are very rare and will very likely slip through such testing. To catch these errors they employ model checking (with TLA+).
\\\\
The PlusCal or TLA+ specifications work as a tool to bridge the gap between design and implementation. Designs are expressive, but inprecise while the implementation is precise, but hides overall structure. Through a choice of abstraction level, specifications can bridge this gap and provide both. An expressive specification also provides useful documentation of the system.
\\\\
The key benefits of model checkers at Amazon are:
\begin{itemize}
    \item a precisely specified design helps make changes and optimizations safely. This usage improves system understanding.
    \item they are faster than formal proofs
    \item a correct design and the understanding the specs provide promote better, more correct code.
\end{itemize}

\section{Temporal Logics}\label{sec:TL}
\paragraph{The Temporal Logic of Programs \cite{Pnueli1977}}
In The Temporal Logic of Programs\cite{Pnueli1977}, Amir Pnueli proposes a unified approach to the verification of both sequential and concurrent programs. His work seeks to unify approaches to to both, while also presenting a system that emulates the design intuition of programmers. The key concepts in this work are \textit{invariance} -- which covers partial correctness, clean behavior, mutual exlusion and deadlock freedom -- and \textit{eventuality} -- which generalizes these notions to cyclic programs and provides a special case of total correctness.
\\\\
A dynamic discrete system is generalized as a three-tuple $\langle S, R, s_0 \rangle$ where $S$ is the set of possible states, $R$ a transition relation, and $s_0$ the initial state of the system. In order to make later constructions easier we further specify
$$s = \langle \pi, u \rangle$$ where $\pi$ is the control component specifying the location in the program and $u$ is the data component describing the state of any variables and data structures, and
$$R(\pi, u) = N(\pi, u) \land T(\pi, u)$$ where $N$ describes the control flow and T the change in data such that a step in the execution may be described by
$$R(\langle \pi, u \rangle , \langle \pi', u' \rangle) \iff \pi' = N(\pi, u) \land u' = T(\pi, u)$$
To reason about concurrent programs we let states have multiple control components $s = \langle \pi_1, \pi_2,...,\pi_n, u \rangle$ and randomly choose one control component to update in each step. Finally we let $X$ be the set of all reachable states for the system. A predicate $p(s)$ is \textbf{invariant} if $p(s)$ is true $\forall s \in X$.
\\\\
We can now start to define useful properties of the systems described in this way.
\begin{itemize}[label={}]
    \item \textbf{Partial correctness} is the claim that given the correct input, a program produces the correct output. We let $\phi(x)$ be the statement "reaching the end state $\implies$ (correct input $\implies$ correct output)". Partial correctness is equivalent to saying $\phi$ is an invariant.
    \item \textbf{Clean execution} means the program does not behave illegally, i.e it does not access illegal memory locations or divide by zero. We may define these restrictions as a predicate to make clean execution equivalent to this predicate being invariant.
    \item \textbf{Mutual exclusion}. Given a critical section $C$, mutual exclusion of the processes $\pi_1$ and $\pi_2$ is described by the invariance of the predicate $\lnot(\pi_1 \in C \land \pi_2 \in C)$.
\end{itemize}
In addition to these properties we wish to reason about \textit{temporal} implications. We let time be described by a $t \in \N$ and $H(p,t)$ denote the value of the predicate $p$ at time $t$.
We then introduce the temporal operator $p \eventually q$ to mean $p$ eventually leads to $q$, or formally:
$$p \eventually q: \forall t_1 \exists t_2\ s.t\ t_1 \le t_2,  H(p, t_1) \implies H(q, t_2)$$
For all times $t_1$ there is a later time $t_2$ such that if $p$ holds at $t_1$, $q$ will hold at $t_2$.
Armed with eventuality we can define temporally useful properties of systems.
\begin{itemize}[label={}]
    \item \textbf{Total correctness} is stronger than partial correctness because it also requires that the program reaches an end state. We can express total correctness as $\langle \pi = l_0, u = \phi\rangle \eventually \langle \pi = l_m, u = \psi\rangle$ where $\phi$ denotes correct input, and $\psi$ denotes correct output and $l_0$, $l_m$ are the start and end labeles of the system, respectively.
    \item \textbf{Accessibility} is the guarantee that some segment $S$ of a program can be reached. It can be expressed by $\pi = l_0 \eventually \pi \in S$
    \item \textbf{Responsiveness}. It is often desirable that some request $r$ will be met by a response $s$. We call this responsiveness and describe it by $r \eventually s$.
\end{itemize}

With these definitions under our belt, Pnueli defines the necessary axioms and inference rules to reason about the correctness of programs.

\begin{figure}[h!]
    \begin{equation}\tag{A1}\label{axiom:1}
        [\forall s, s' p(s) \land R(s,s') \implies q(s')] \Rightarrow p \eventually q
    \end{equation}
    \begin{equation}\tag{A2}\label{axiom:2}
        (p \implies q) \Rightarrow p \eventually q
    \end{equation}
\caption{Pnueli's axioms}
\end{figure}

These axioms define two ways to establish eventuality. \ref{axiom:2} says that any logical implication is also an eventuality. \ref{axiom:1} is a little more involved, but states that if for all consecutive states $p$ being true in the first implies $q$ being true in the second, then $p$ eventually leads to $q$.

\begin{figure}[h]
    \begin{equation}\tag{R1}\label{rules:1}
        p \eventually q, \forall s, s' r(s) \land R(s,s') \implies r(s') \Rightarrow (p \land r) \eventually (q \land r)
    \end{equation}
    \begin{equation}\tag{R2}\label{rules:2}
        p \eventually q, q \eventually r \Rightarrow p \eventually r
    \end{equation}
    \begin{equation}\tag{R3}\label{rules:3}
        p_1 \eventually q, p_2 \eventually q \Rightarrow (p_1 \lor p_2) \eventually q
    \end{equation}
    \begin{equation}\tag{R4}\label{rules:4}
        p \eventually q \Rightarrow (\exists u p) \eventually q
    \end{equation}
\caption{Pnueli's inference rules}
\end{figure}

Using these axioms and inference rules as well as first-order logic, Pnueli goes on to formalize invariance and eventuality for sequential programs and concurrent programs.

\begin{itemize}[label={}]
    \item \textbf{Invariance} of the predicate $q(\pi, u)$ is described by the conjunction $\bigwedge\limits_{i}{\pi=l_i \implies q(l_i, u)}$, asserting that $q$ is true at all points of execution. This method is called an \textit{attachment} of the predicate to the program.
    \newpage{}
    In a concurrent program we generalize $q$ to hold when any $\pi_i$ is updated by $N$ and construct either a full attachment
    $$\bigwedge\limits_{i_1, i_2,...,i_n}{(\pi_1 = i_1 \land \pi_2 = i_2 \land ... \land \pi_n = i_n) \implies q(\pi_1,..,\pi_n,u)}$$ shown here for $n$ concurrent execution threads,
    or the partial attachment
    $$\bigwedge\limits_{i}{\pi_1=i \implies q(\pi_1 = i, \pi_2, u)} \land \bigwedge\limits_{j}{\pi_2=j \implies q(\pi_1, \pi_2 = j, u)}$$ shown here for two threads $\pi_1$ and $\pi_2$.
    \item \textbf{Eventuality} is formulated as the temporal implication $\pi = l_1 \land p(u) \eventually \pi=l_2 \land q(u)$. We can then describe the path between $l_1$ and $l_2$ by a finite sequence of steps and apply \ref{axiom:1} to each step.
\end{itemize}

Finally, Pnueli introduces two new "tense operators" \textbf{F}uture and \textbf{G}lobal on predicates such that at some time $n$
$$F(p) = \exists t \geq n \; s.t\; H(t,p)$$
$$G(p) = \forall t \geq n \; H(t,p)$$
This lets us describe useful properties such as
\begin{itemize}[label={}]
    \item $p \implies F(q)$ -- if $p$ is true now, then at some point in the future $q$ will be true.
    \item $G(p \implies F(q))$ -- whenever $p$ is true it will eventually be followed by a state in which $q$ is true. (this is equivalent to $p \eventually q$)     
\end{itemize}
\section{TLA+}\label{sec:TLA+}
\section{Split-Ordered List Hashmap}\label{sec:hashmap}

Maybe a description of hashmaps in general here to set up the later use of table, list, key etc. or is that assumed knowledge?
\\\\
Shalev et al.\cite{Shalev2006} present the first lock-free extensible hash table implemented using only loads, stores and atomic Compare and Swap (CAS).
\\\\
Hashmaps are a key building block in many important systems [citation needed], but are difficult to implement concurrently. In particular, the resizing (extending) of the table is difficult to do atomically because at the very least a node must be moved from one list to another. In order to avoid conflicts and loss of data in this process some overhead is required which impacts performance.
\\\\
The key insight of Shalev et al. is to flip the process upside down. Instead of moving nodes between buckets, they suggest moving the buckets among a statically ordered list of nodes. This requires an ordering of the list in which a bucket can always be split into two new buckets while their contents remain correct. A node should always reside in the bucket corresponding to its key $\mod 2^i$ where $2^i$ is the current size of the table.

\paragraph{Split-Ordered Lists}
are introduced to solve this problem. By sorting the keys according to their reversed binary representation Shalev et al. obtain a list which can be always be split into buckets $\mod 2^i$. This is because such an ordering corresponds to difference in the keys' $i$th least significant bit, which is equivalent to having a different remainder $\mod 2^i$.
\\\\
\begin{figure}
    \includegraphics[width=\textwidth]{split-ordered-list-diagram.png}
\caption{The layout of the split-ordered list}
\label{fig:split-order}
\end{figure}
In order to deal with the problems caused by removing nodes pointed to by hash table entries dummy nodes with the bucket value are introduced. These nodes signify the start of a bucket and are recursively initialized when an item is inserted into an unitialized bucket. To distinguish dummy nodes from regular nodes in the list, regular node keys have their most significant bit set to 1 before being reversed. This order and the structure of the map can be seen in \autoref{fig:split-order}.

\begin{figure}
    \centering
    \subfloat[Initial state]{\includegraphics[width=.5\textwidth]{insert-0.png}}
    \subfloat[Dummy node is created]{\includegraphics[width=.5\textwidth]{insert-1.png}}
    \newline
    \subfloat[Dummy node is inserted in bucket]{\includegraphics[width=.5\textwidth]{insert-2.png}}
    \subfloat[New node is inserted]{\includegraphics[width=.5\textwidth]{insert-3.png}}
\caption{Insertion without bucket splitting}
\label{fig:simple-insert}
\end{figure}

\begin{figure}
    \centering
    \subfloat[Initial state]{\includegraphics[height=2in]{expand-0.png}}
    \newline
    \subfloat[Table is expanded]{\includegraphics[height=2in]{expand-1.png}}
    \newline
    \subfloat[Dummy node for new bucket inserted]{\includegraphics[height=2in]{expand-2.png}}
    \newline
    \subfloat[Table entry points to bucket node]{\includegraphics[height=2in]{expand-3.png}}
\caption{Expansion and bucket splitting}
\label{fig:insert-expand}
\end{figure}

Insertion in to the map is done through atomic CAS instructions on the list. If a bucket is not initialized, a dummy node is created and inserted into the list before the new value is added as shown in \autoref{fig:simple-insert}. The map is expanded by doubling the number of buckets and inserting new dummy nodes. Because of the split-ordering of the list, it is always possible to insert a new bucket by splitting an existing one. This process is shown in \autoref{fig:insert-expand}.


\chapter{TLA+ Specification}\label{ch:specification}
\chapter{Results}\label{ch:results}
\section{Discussion}\label{sec:discussion}

\backmatter

\printbibliography{}

\end{document}
